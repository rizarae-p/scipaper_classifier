TY  - JOUR
TI  - Comparing Inertial Measurement Units to Markerless Video Analysis for Movement Symmetry in Quarter Horses
AU  - Pfau, Thilo
AU  - Landsbergen, Kiki
AU  - Davis, Brittany L.
AU  - Kenny, Olivia
AU  - Kernot, Nicole
AU  - Rochard, Nina
AU  - Porte-Proust, Marion
AU  - Sparks, Holly
AU  - Takahashi, Yuji
AU  - Toth, Kasara
AU  - Scott, W. Michael
T2  - Sensors
DO  - 10.3390/s23208414
U1  - 37896509
U2  - PMC10610735
AB  - Background: With an increasing number of systems for quantifying lameness-related movement asymmetry, between-system comparisons under non-laboratory conditions are important for multi-centre or referral-level studies. This study compares an artificial intelligence video app to a validated inertial measurement unit (IMU) gait analysis system in a specific group of horses. Methods: Twenty-two reining Quarter horses were equipped with nine body-mounted IMUs while being videoed with a smartphone app. Both systems quantified head and pelvic movement symmetry during in-hand trot (hard/soft ground) and on the lunge (left/right rein, soft ground). Proportional limits of agreement (pLoA) were established. Results: Widths of pLoA were larger for head movement (29% to 50% in-hand; 22% to 38% on lunge) than for pelvic movement (13% to 24% in-hand; 14% to 24% on lunge). Conclusion: The between-system pLoAs exceed current “lameness thresholds” aimed at identifying the affected limb(s) in lame horses. They also exceed published limits of agreement for stride-matched data but are similar to repeatability values and “lameness thresholds” from “non-lame” horses. This is encouraging for multi-centre studies and referral-level veterinary practice. The narrower pLoA values for pelvic movement asymmetry are particularly encouraging, given the difficulty of grading hind limb lameness “by eye”.
J2  - Sensors
SP  - 8414
IS  - 20
VL  - 23
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/30e5f776-daae-4530-87c6-99346c5f10c0
XX  - 
PMID  - 37896509
ER  - 

TY  - JOUR
TI  - The role of hydrodynamics in collective motions of fish schools and bioinspired underwater robots
AU  - Ko, Hungtang
AU  - Lauder, George
AU  - Nagpal, Radhika
T2  - Journal of the Royal Society Interface
SN  - 1742-5689
DO  - 10.1098/rsif.2023.0357
U1  - 37876271
U2  - PMC10598440
AB  - Collective behaviour defines the lives of many animal species on the Earth. Underwater swarms span several orders of magnitude in size, from coral larvae and krill to tunas and dolphins. Agent-based algorithms have modelled collective movements of animal groups by use of social forces, which approximate the behaviour of individual animals. But details of how swarming individuals interact with the fluid environment are often under-examined. How do fluid forces shape aquatic swarms? How do fish use their flow-sensing capabilities to coordinate with their schooling mates? We propose viewing underwater collective behaviour from the framework of fluid stigmergy, which considers both physical interactions and information transfer in fluid environments. Understanding the role of hydrodynamics in aquatic collectives requires multi-disciplinary efforts across fluid mechanics, biology and biomimetic robotics. To facilitate future collaborations, we synthesize key studies in these fields.
J2  - J. R. Soc. Interface
SP  - 20230357
IS  - 207
VL  - 20
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/38c7e166-ce8b-4068-b5b7-72eaa730dedb
XX  - 
PMID  - 37876271
ER  - 

TY  - JOUR
TI  - Challenges and advanced concepts for the assessment of learning and memory function in mice
AU  - Lang, Benjamin
AU  - Kahnau, Pia
AU  - Hohlbaum, Katharina
AU  - Mieske, Paul
AU  - Andresen, Niek P.
AU  - Boon, Marcus N.
AU  - Thöne-Reineke, Christa
AU  - Lewejohann, Lars
AU  - Diederich, Kai
T2  - Frontiers in Behavioral Neuroscience
SN  - 1662-5153
DO  - 10.3389/fnbeh.2023.1230082
U1  - 37809039
U2  - PMC10551171
AB  - The mechanisms underlying the formation and retrieval of memories are still an active area of research and discussion. Manifold models have been proposed and refined over the years, with most assuming a dichotomy between memory processes involving non-conscious and conscious mechanisms. Despite our incomplete understanding of the underlying mechanisms, tests of memory and learning count among the most performed behavioral experiments. Here, we will discuss available protocols for testing learning and memory using the example of the most prevalent animal species in research, the laboratory mouse. A wide range of protocols has been developed in mice to test, e.g., object recognition, spatial learning, procedural memory, sequential problem solving, operant- and fear conditioning, and social recognition. Those assays are carried out with individual subjects in apparatuses such as arenas and mazes, which allow for a high degree of standardization across laboratories and straightforward data interpretation but are not without caveats and limitations. In animal research, there is growing concern about the translatability of study results and animal welfare, leading to novel approaches beyond established protocols. Here, we present some of the more recent developments and more advanced concepts in learning and memory testing, such as multi-step sequential lockboxes, assays involving groups of animals, as well as home cage-based assays supported by automated tracking solutions; and weight their potential and limitations against those of established paradigms. Shifting the focus of learning tests from the classical experimental chamber to settings which are more natural for rodents comes with a new set of challenges for behavioral researchers, but also offers the opportunity to understand memory formation and retrieval in a more conclusive way than has been attainable with conventional test protocols. We predict and embrace an increase in studies relying on methods involving a higher degree of automatization, more naturalistic- and home cage-based experimental setting as well as more integrated learning tasks in the future. We are confident these trends are suited to alleviate the burden on animal subjects and improve study designs in memory research.
J2  - Front. Behav. Neurosci.
SP  - 1230082
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/97c8f215-bd9f-4278-8fa5-d84989f21d34
XX  - 
PMID  - 37809039
ER  - 

TY  - JOUR
TI  - DVT: a high-throughput analysis pipeline for locomotion and social behavior in adult Drosophila melanogaster
AU  - Mi, Kai
AU  - Li, Yiqing
AU  - Yang, Yuhang
AU  - Secombe, Julie
AU  - Liu, Xingyin
T2  - Cell & Bioscience
SN  - 2045-3701
DO  - 10.1186/s13578-023-01125-0
U1  - 37798731
U2  - PMC10557313
AB  - Drosophila melanogaster is excellent animal model for understanding the molecular basis of human neurological and motor disorders. The experimental conditions and chamber design varied between studies. Moreover, most previously established paradigms focus on fly trace detection algorithm development. A comprehensive understanding on how fly behaves in the chamber is still lacking. In this report, we established 74 unique behavior metrics quantifying spatiotemporal characteristics of adult fly locomotion and social behaviors, of which 49 were newly proposed. By the aiding of the developed analysis pipeline, Drosophila video tracking (DVT), we identified siginificantly different patterns of fly behavior confronted with different chamber height, fly density, illumination and experimental time. Meanwhile, three fly strains which are widely used as control lines, Canton-S(CS), w1118 and Oregon-R (OR), were found to exhibit distinct motion explosiveness and exercise endurance. We believe the proposed behavior metrics set and pipeline should help identify subtle spatial and temporal differences of drosophila behavior confronted with different environmental factors or gene variants.
J2  - Cell Biosci.
SP  - 187
IS  - 1
VL  - 13
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/dc36e1a5-cb76-4e1a-9d0a-820ba81a0926
XX  - 
PMID  - 37798731
ER  - 

TY  - JOUR
TI  - Multi-animal pose estimation, identification and tracking with DeepLabCut
AU  - Lauer, Jessy
AU  - Zhou, Mu
AU  - Ye, Shaokai
AU  - Menegas, William
AU  - Schneider, Steffen
AU  - Nath, Tanmay
AU  - Rahman, Mohammed Mostafizur
AU  - Santo, Valentina Di
AU  - Soberanes, Daniel
AU  - Feng, Guoping
AU  - Murthy, Venkatesh N.
AU  - Lauder, George
AU  - Dulac, Catherine
AU  - Mathis, Mackenzie Weygandt
AU  - Mathis, Alexander
T2  - Nature Methods
SN  - 1548-7091
DO  - 10.1038/s41592-022-01443-0
U1  - 35414125
U2  - PMC9007739
AB  - Estimating the pose of multiple animals is a challenging computer vision problem: frequent interactions cause occlusions and complicate the association of detected keypoints to the correct individuals, as well as having highly similar looking animals that interact more closely than in typical multi-human scenarios. To take up this challenge, we build on DeepLabCut, an open-source pose estimation toolbox, and provide high-performance animal assembly and tracking—features required for multi-animal scenarios. Furthermore, we integrate the ability to predict an animal’s identity to assist tracking (in case of occlusions). We illustrate the power of this framework with four datasets varying in complexity, which we release to serve as a benchmark for future algorithm development. DeepLabCut is extended to enable multi-animal pose estimation, animal identification and tracking, thereby enabling the analysis of social behaviors.
J2  - Nat. Methods
SP  - 496-504
IS  - 4
VL  - 19
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/f9dd07c5-5f6d-4405-b28e-8d7adb240a3e
XX  - 
PMID  - 35414125
ER  - 

TY  - JOUR
TI  - A unified open-source platform for multimodal neural recording and perturbation during naturalistic behavior
AU  - Newman, Jonathan P.
AU  - Zhang, Jie
AU  - Cuevas-López, Aarón
AU  - Miller, Nicholas J.
AU  - Honda, Takato
AU  - Goes, Marie-Sophie H. van der
AU  - Leighton, Alexandra H.
AU  - Carvalho, Filipe
AU  - Lopes, Gonçalo
AU  - Lakunina, Anna
AU  - Siegle, Joshua H.
AU  - Harnett, Mark T.
AU  - Wilson, Matthew A.
AU  - Voigts, Jakob
T2  - bioRxiv
DO  - 10.1101/2023.08.30.554672
U1  - 37693443
U2  - PMC10491150
AB  - Behavioral neuroscience faces two conflicting demands: long-duration recordings from large neural populations and unimpeded animal behavior. To meet this challenge, we developed ONIX, an open-source data acquisition system with high data throughput (2GB/sec) and low closed-loop latencies (<1ms) that uses a novel 0.3 mm thin tether to minimize behavioral impact. Head position and rotation are tracked in 3D and used to drive active commutation without torque measurements. ONIX can acquire from combinations of passive electrodes, Neuropixels probes, head-mounted microscopes, cameras, 3D-trackers, and other data sources. We used ONIX to perform uninterrupted, long (∼7 hours) neural recordings in mice as they traversed complex 3-dimensional terrain. ONIX allowed exploration with similar mobility as non-implanted animals, in contrast to conventional tethered systems which restricted movement. By combining long recordings with full mobility, our technology will enable new progress on questions that require high-quality neural recordings during ethologically grounded behaviors.
J2  - bioRxiv
SP  - 2023.08.30.554672
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/1c6f36a9-4b21-46f2-afd9-7d75c648b245
XX  - 
PMID  - 37693443
ER  - 

TY  - JOUR
TI  - Protocol to investigate the neural basis for copulation posture of Drosophila using a closed-loop real-time optogenetic system
AU  - Yamanouchi, Hayato M.
AU  - Kamikouchi, Azusa
AU  - Tanaka, Ryoya
T2  - STAR Protocols
SN  - 2666-1667
DO  - 10.1016/j.xpro.2023.102623
U1  - 37788165
U2  - PMC10551656
AB  - In internal fertilization animals, maintaining a copulation posture facilitates the process of transporting gametes from male to female. Here, we present a protocol to investigate the neural basis for copulation posture of fruit flies using a closed-loop real-time optogenetic system. We describe steps for using deep learning analysis to enable optogenetic manipulation of neural activity only during copulation with high efficiency. This system can be applied to various animal behaviors other than copulation. For complete details on the use and execution of this protocol, please refer to Yamanouchi et al. (2023). 1
J2  - STAR Protoc.
SP  - 102623
IS  - 4
VL  - 4
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/24c2d276-544e-4114-99d4-50e122791d72
XX  - 
PMID  - 37788165
ER  - 

TY  - JOUR
TI  - Quantifying agonistic interactions between group-housed animals to derive social hierarchies using computer vision: a case study with commercially group-housed rabbits
AU  - Ipek, Nusret
AU  - Damme, Liesbeth G. W. Van
AU  - Tuyttens, Frank A. M.
AU  - Verwaeren, Jan
T2  - Scientific Reports
DO  - 10.1038/s41598-023-41104-6
U1  - 37644059
U2  - PMC10465565
AB  - In recent years, computer vision has contributed significantly to the study of farm animal behavior. In complex environments such as commercial farms, however, the automated detection of social behavior and specific interactions between animals can be improved. The present study addresses the automated detection of agonistic interactions between caged animals in a complex environment, relying solely on computer vision. An automated pipeline including group-level temporal action segmentation, object detection, object tracking and rule-based action classification for the detection of agonistic interactions was developed and extensively validated at a level unique in the field. Comparing with observations made by human observers, our pipeline reaches 77% precision and 85% recall using a 5-min tolerance interval for the detection of agonistic interactions. Results obtained using this pipeline allow to construct time-dependent socio-matrices of a group of animals and derive metrics on the dominance hierarchy in a semi-automated manner. Group-housed breeding rabbits (does) with their litters in commercial farms are the main use-case in this work, but the idea is probably also applicable to other social farm animals.
J2  - Sci. Rep.
SP  - 14138
IS  - 1
VL  - 13
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/6a3d3c31-7985-48a7-bcbb-c55a9a7f7783
XX  - 
PMID  - 37644059
ER  - 

TY  - JOUR
TI  - Review of Environmental and Health Factors Impacting Captive Common Marmoset Welfare in the Biomedical Research Setting
AU  - Burns, Monika
T2  - Veterinary Sciences
DO  - 10.3390/vetsci10090568
U1  - 37756090
U2  - PMC10535419
AB  - Common marmosets (Callithrix jacchus) are a small neotropical species of nonhuman primate that are commonly kept in captivity in zoological and biomedical research settings. The use of nonhuman primates in biomedical research has been critical to many advances that have allowed for the treatment of human diseases. The use of marmosets in research has increased in recent years. While there are some publications that describe best practices for their care and use in biomedical research settings, there is a need to develop additional reference guidelines. This manuscript reviews and summarizes publications related to the unique needs of marmosets kept in biomedical research settings and provides a comprehensive review of factors that should be considered by all staff working with these animals in order to promote optimal health and research use. This manuscript also highlights environmental and other factors that may impact marmoset welfare and provides recommendations on how best to plan for, care for, and work with marmosets in a biomedical research setting. As a small-bodied neotropical nonhuman primate species, common marmosets have unique requirements for adequate husbandry and veterinary care to ensure proper maintenance and to promote good animal welfare in a biomedical research setting. Environmental conditions, as well as medical and research-related manipulations, can impact marmoset welfare. Research focus areas, including basic neuroscience, transgenics, and aging, involve additional implications for marmoset welfare. This manuscript provides a comprehensive review of factors that should be considered and mitigated as needed by clinical and research staff working with marmosets in biomedical research facilities to optimize the welfare of captive marmosets.
J2  - Vet. Sci.
SP  - 568
IS  - 9
VL  - 10
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/8fb772b1-a6fb-4003-80a1-f3164bc83e8a
XX  - 
PMID  - 37756090
ER  - 

TY  - JOUR
TI  - Large-scale capture of hidden fluorescent labels for training generalizable markerless motion capture models
AU  - Butler, Daniel J.
AU  - Keim, Alexander P.
AU  - Ray, Shantanu
AU  - Azim, Eiman
T2  - Nature Communications
DO  - 10.1038/s41467-023-41565-3
U1  - 37752123
U2  - PMC10522643
AB  - Deep learning-based markerless tracking has revolutionized studies of animal behavior. Yet the generalizability of trained models tends to be limited, as new training data typically needs to be generated manually for each setup or visual environment. With each model trained from scratch, researchers track distinct landmarks and analyze the resulting kinematic data in idiosyncratic ways. Moreover, due to inherent limitations in manual annotation, only a sparse set of landmarks are typically labeled. To address these issues, we developed an approach, which we term GlowTrack, for generating orders of magnitude more training data, enabling models that generalize across experimental contexts. We describe: a) a high-throughput approach for producing hidden labels using fluorescent markers; b) a multi-camera, multi-light setup for simulating diverse visual conditions; and c) a technique for labeling many landmarks in parallel, enabling dense tracking. These advances lay a foundation for standardized behavioral pipelines and more complete scrutiny of movement. Deep learning-based models for tracking behavior are often constrained by manual annotation. Here, authors present GlowTrack, an approach using fluorescence to generate large and diverse training sets that improve model robustness and tracking coverage.
J2  - Nat. Commun.
SP  - 5866
IS  - 1
VL  - 14
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/b2476431-4faf-4762-a588-16096a9e31ad
XX  - 
PMID  - 37752123
ER  - 

TY  - JOUR
TI  - Accelerating the characterization of dynamic DNA origami devices with deep neural networks
AU  - Wang, Yuchen
AU  - Jin, Xin
AU  - Castro, Carlos
T2  - Scientific Reports
DO  - 10.1038/s41598-023-41459-w
U1  - 37709771
U2  - PMC10502017
AB  - Mechanical characterization of dynamic DNA nanodevices is essential to facilitate their use in applications like molecular diagnostics, force sensing, and nanorobotics that rely on device reconfiguration and interactions with other materials. A common approach to evaluate the mechanical properties of dynamic DNA nanodevices is by quantifying conformational distributions, where the magnitude of fluctuations correlates to the stiffness. This is generally carried out through manual measurement from experimental images, which is a tedious process and a critical bottleneck in the characterization pipeline. While many tools support the analysis of static molecular structures, there is a need for tools to facilitate the rapid characterization of dynamic DNA devices that undergo large conformational fluctuations. Here, we develop a data processing pipeline based on Deep Neural Networks (DNNs) to address this problem. The YOLOv5 and Resnet50 network architecture were used for the two key subtasks: particle detection and pose (i.e. conformation) estimation. We demonstrate effective network performance (F1 score 0.85 in particle detection) and good agreement with experimental distributions with limited user input and small training sets (~ 5 to 10 images). We also demonstrate this pipeline can be applied to multiple nanodevices, providing a robust approach for the rapid characterization of dynamic DNA devices.
J2  - Sci. Rep.
SP  - 15196
IS  - 1
VL  - 13
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/f8f1ab1f-a213-4a91-b4ea-17f1e4299d1b
XX  - 
PMID  - 37709771
ER  - 

TY  - JOUR
TI  - The neurobiology of vocal communication in marmosets
AU  - Grijseels, Dori M.
AU  - Prendergast, Brendan J.
AU  - Gorman, Julia C.
AU  - Miller, Cory T.
T2  - Annals of the New York Academy of Sciences
SN  - 0077-8923
DO  - 10.1111/nyas.15057
U1  - 37615212
U2  - PMC10592205
AB  - An increasingly popular animal model for studying the neural basis of social behavior, cognition, and communication is the common marmoset (Callithrix jacchus). Interest in this New World primate across neuroscience is now being driven by their proclivity for prosociality across their repertoire, high volubility, and rapid development, as well as their amenability to naturalistic testing paradigms and freely moving neural recording and imaging technologies. The complement of these characteristics set marmosets up to be a powerful model of the primate social brain in the years to come. Here, we focus on vocal communication because it is the area that has both made the most progress and illustrates the prodigious potential of this species. We review the current state of the field with a focus on the various brain areas and networks involved in vocal perception and production, comparing the findings from marmosets to other animals, including humans. The common marmoset (Callithrix jacchus) is an increasingly popular animal model for the study of vocal communication. Here, we review the neurobiology underlying this primate's vocal communication system focusing on brain networks of vocal perception and production. Additionally, we discuss how recent technical advances will allow for the study of vocal communication and its underlying neurobiology in natural, behavioral contexts.
J2  - Ann. N. York Acad. Sci.
SP  - 13-28
IS  - 1
VL  - 1528
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/0c96a796-7a70-4f9e-b5f6-e48a050ac125
XX  - 
PMID  - 37615212
ER  - 

TY  - JOUR
TI  - Comparative neurogenetics of dog behavior complements efforts towards human neuropsychiatric genetics
AU  - Morrill, Kathleen
AU  - Chen, Frances
AU  - Karlsson, Elinor
T2  - Human Genetics
SN  - 0340-6717
DO  - 10.1007/s00439-023-02580-y
U1  - 37578529
AB  - Domestic dogs display a wide array of heritable behaviors that have intermediate genetic complexity thanks to a long history of human-influenced selection. Comparative genetics in dogs could address the scarcity of non-human neurogenetic systems relevant to human neuropsychiatric disorders, which are characterized by mental, emotional, and behavioral symptoms and involve vastly complex genetic and non-genetic risk factors. Our review describes the diverse behavioral “phenome” of domestic dogs, past and ongoing sources of behavioral selection, and the state of canine behavioral genetics. We highlight two naturally disordered behavioral domains that illustrate how dogs may prove useful as a comparative, forward neurogenetic system: canine age-related cognitive dysfunction, which can be examined more rapidly given the attenuated lifespan of dogs, and compulsive disorders, which may have genetic roots in purpose-bred behaviors. Growing community science initiatives aimed at the companion dog population will be well suited to investigating such complex behavioral phenotypes and offer a comparative resource that parallels human genomic initiatives in scale and dimensionality.
J2  - Hum. Genet.
SP  - 1231-1246
IS  - 8
VL  - 142
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/619a7611-f59f-4526-88a9-b56fbef2f266
XX  - 
PMID  - 37578529
ER  - 

TY  - JOUR
TI  - IMFSegNet: Cost-effective and objective quantification of intramuscular fat in histological sections by deep learning
AU  - Praetorius, Jan-Philipp
AU  - Walluks, Kassandra
AU  - Svensson, Carl-Magnus
AU  - Arnold, Dirk
AU  - Figge, Marc Thilo
T2  - Computational and Structural Biotechnology Journal
SN  - 2001-0370
DO  - 10.1016/j.csbj.2023.07.031
U1  - 37560127
U2  - PMC10407270
AB  - The assessment of muscle condition is of great importance in various research areas. In particular, evaluating the degree of intramuscular fat (IMF) in tissue sections is a challenging task, which today is still mostly performed qualitatively or quantitatively by a highly subjective and error-prone manual analysis. We here realize the mission to make automated IMF analysis possible that (i) minimizes subjectivity, (ii) provides accurate and quantitative results quickly, and (iii) is cost-effective using standard hematoxylin and eosin (H&E) stained tissue sections. To address all these needs in a deep learning approach, we utilized the convolutional encoder-decoder network SegNet to train the specialized network IMFSegNet allowing to accurately quantify the spatial distribution of IMF in histological sections. Our fully automated analysis was validated on 17 H&E-stained muscle sections from individual sheep and compared to various state-of-the-art approaches. Not only does IMFSegNet outperform all other approaches, but this neural network also provides fully automated and highly accurate results utilizing the most cost-effective procedures of sample preparation and imaging. Furthermore, we shed light on the opacity of black-box approaches such as neural networks by applying an explainable artificial intelligence technique to clarify that the success of IMFSegNet actually lies in identifying the hard-to-detect IMF structures. Embedded in our open-source visual programming language JIPipe that does not require programming skills, it can be expected that IMFSegNet advances muscle condition assessment in basic research across multiple areas as well as in research fields focusing on translational clinical applications.
J2  - Comput. Struct. Biotechnol. J.
SP  - 3696-3704
VL  - 21
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/a7bea9ea-4489-4e93-a7de-157179e83df5
XX  - 
PMID  - 37560127
ER  - 

TY  - JOUR
TI  - PiE: an open-source pipeline for home cage behavioral analysis
AU  - Benedict, Jessie
AU  - Cudmore, Robert H.
T2  - Frontiers in Neuroscience
SN  - 1662-4548
DO  - 10.3389/fnins.2023.1222644
U1  - 37583418
U2  - PMC10423934
AB  - Over the last two decades a growing number of neuroscience labs are conducting behavioral assays in rodents. The equipment used to collect this behavioral data must effectively limit environmental and experimenter disruptions, to avoid confounding behavior data. Proprietary behavior boxes are expensive, offer limited compatible sensors, and constrain analysis with closed-source hardware and software. Here, we introduce PiE, an open-source, end-to-end, user-configurable, scalable, and inexpensive behavior assay system. The PiE system includes the custom-built behavior box to hold a home cage, as well as software enabling continuous video recording and individual behavior box environmental control. To limit experimental disruptions, the PiE system allows the control and monitoring of all aspects of a behavioral experiment using a remote web browser, including real-time video feeds. To allow experiments to scale up, the PiE system provides a web interface where any number of boxes can be controlled, and video data easily synchronized to a remote location. For the scoring of behavior video data, the PiE system includes a standalone desktop application that streamlines the blinded manual scoring of large datasets with a focus on quality control and assay flexibility. The PiE system is ideal for all types of behavior assays in which video is recorded. Users are free to use individual components of this setup independently, or to use the entire pipeline from data collection to analysis. Alpha testers have included scientists without prior coding experience. An example pipeline is demonstrated with the PiE system enabling the user to record home cage maternal behavior assays, synchronize the resulting data, conduct blinded scoring, and import the data into R for data visualization and analysis.
J2  - Front. Neurosci.
SP  - 1222644
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/b7ef3043-d199-4e4c-9d90-175a0606a7e7
XX  - 
PMID  - 37583418
ER  - 

TY  - JOUR
TI  - A Year at the Forefront of Hydrostat Motion
AU  - Schulz, Andrew K.
AU  - Schneider, Nikole
AU  - Zhang, Margaret
AU  - Singal, Krishma
T2  - Biology Open
DO  - 10.1242/bio.059834
U1  - 37566395
U2  - PMC10434360
AB  - Currently, in the field of interdisciplinary work in biology, there has been a significant push by the soft robotic community to understand the motion and maneuverability of hydrostats. This Review seeks to expand the muscular hydrostat hypothesis toward new structures, including plants, and introduce innovative techniques to the hydrostat community on new modeling, simulating, mimicking, and observing hydrostat motion methods. These methods range from ideas of kirigami, origami, and knitting for mimic creation to utilizing reinforcement learning for control of bio-inspired soft robotic systems. It is now being understood through modeling that different mechanisms can inhibit traditional hydrostat motion, such as skin, nostrils, or sheathed layered muscle walls. The impact of this Review will highlight these mechanisms, including asymmetries, and discuss the critical next steps toward understanding their motion and how species with hydrostat structures control such complex motions, highlighting work from January 2022 to December 2022.
J2  - Biol. Open
SP  - bio059834
IS  - 8
VL  - 12
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/d495e8a9-ec76-4f92-94a3-6efb1e9fd6c7
XX  - 
PMID  - 37566395
ER  - 

TY  - JOUR
TI  - Shared science’s time to shine
AU  - Harrison, Charlotte
T2  - Lab Animal
SN  - 0093-7355
DO  - 10.1038/s41684-023-01219-9
U1  - 37524949
AB  - Sharing research tools and data with other scientists brings many benefits, such as using fewer animals, improving reproducibility and increasing study sample size, but the practice still needs to be more widely adopted.
J2  - Lab Anim.
SP  - 179-182
IS  - 8
VL  - 52
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/416f4691-2ddc-4db6-9b38-653a2b1abd72
XX  - 
PMID  - 37524949
ER  - 

TY  - JOUR
TI  - Disentangling rodent behaviors to improve automated behavior recognition
AU  - Dam, Elsbeth A. Van
AU  - Noldus, Lucas P. J. J.
AU  - Gerven, Marcel A. J. Van
T2  - Frontiers in Neuroscience
SN  - 1662-4548
DO  - 10.3389/fnins.2023.1198209
U1  - 37496740
U2  - PMC10366600
AB  - Automated observation and analysis of behavior is important to facilitate progress in many fields of science. Recent developments in deep learning have enabled progress in object detection and tracking, but rodent behavior recognition struggles to exceed 75–80% accuracy for ethologically relevant behaviors. We investigate the main reasons why and distinguish three aspects of behavior dynamics that are difficult to automate. We isolate these aspects in an artificial dataset and reproduce effects with the state-of-the-art behavior recognition models. Having an endless amount of labeled training data with minimal input noise and representative dynamics will enable research to optimize behavior recognition architectures and get closer to human-like recognition performance for behaviors with challenging dynamics.
J2  - Front. Neurosci.
SP  - 1198209
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/62e38071-0a64-4efa-9afc-51e4de87e56d
XX  - 
PMID  - 37496740
ER  - 

TY  - JOUR
TI  - Seminatural environments for rodent behavioral testing: a representative design improving animal welfare and enhancing replicability
AU  - Hernández-Arteaga, Enrique
AU  - Ågmo, Anders
T2  - Frontiers in Behavioral Neuroscience
SN  - 1662-5153
DO  - 10.3389/fnbeh.2023.1192213
U1  - 37424748
U2  - PMC10323197
AB  - The low replicability of scientific studies has become an important issue. One possible cause is low representativeness of the experimental design employed. Already in the 1950’s, Egon Brunswick pointed out that experimental setups ideally should be based on a random sample of stimuli from the subjects’ natural environment or at least include basic features of that environment. Only experimental designs satisfying this criterion, representative designs in Brunswikian terminology, can produce results generalizable beyond the procedure used and to situations outside the laboratory. Such external validity is crucial in preclinical drug studies, for example, and should be important for replicability in general. Popular experimental setups in rodent research on non-human animals, like the tail suspension test or the Geller-Seifter procedure, do not correspond to contexts likely to be encountered in the animals’ habitat. Consequently, results obtained in this kind of procedures can be generalized neither to other procedures nor to contexts outside the laboratory. Furthermore, many traditional procedures are incompatible with current notions of animal welfare. An approximation to the natural social and physical context can be provided in the laboratory, in the form of a seminatural environment. In addition to satisfy the basic demands for a representative design, such environments offer a far higher level of animal welfare than the typical small cages. This perspective article will briefly discuss the basic principles of the generalizability of experimental results, the virtues of representative designs and the coincidence of enhanced scientific quality and animal welfare provided by this kind of design.
J2  - Front. Behav. Neurosci.
SP  - 1192213
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/6880c2d5-a576-45c8-b739-4221a45b302d
XX  - 
PMID  - 37424748
ER  - 

TY  - JOUR
TI  - Early-life sleep disruption impairs subtle social behaviours in prairie voles: a pose-estimation study
AU  - Bueno-Junior, Lezio S.
AU  - Jones-Tinsley, Carolyn E.
AU  - Milman, Noah E. P.
AU  - Wickham, Peyton T.
AU  - Watson, Brendon O.
AU  - Lim, Miranda M.
T2  - Royal Society Open Science
SN  - 2054-5703
DO  - 10.1098/rsos.230700
U1  - 37448475
U2  - PMC10336370
AB  - Early-life sleep disruption (ELSD) has been shown to have long-lasting effects on social behaviour in adult prairie voles (Microtus ochrogaster), including impaired expression of pair bonding during partner preference testing. However, due to the limitations of manual behaviour tracking, the effects of ELSD across the time course of pair bonding have not yet been described, hindering our ability to trace mechanisms. Here, we used pose estimation to track prairie voles during opposite-sex cohabitation, the process leading to pair bonding. Male–female pairs were allowed to interact through a mesh divider in the home cage for 72 h, providing variables of body direction, distance-to-divider and locomotion speed. We found that control males displayed periodic patterns of body orientation towards females during cohabitation. In contrast, ELSD males showed reduced duration and ultradian periodicity of these body orientation behaviours towards females. Furthermore, in both sexes, ELSD altered spatial and temporal patterns of locomotion across the light/dark cycles of the 72 h recordings. This study allows a comprehensive behavioural assessment of the effects of ELSD on later life sociality and highlights subtle prairie vole behaviours. Our findings may shed light on neurodevelopmental disorders featuring sleep disruption and social deficits, such as autism spectrum disorders.
J2  - R. Soc. Open Sci.
SP  - 230700
IS  - 7
VL  - 10
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/83777677-8c32-4d73-ae1d-eda0958d1109
XX  - 
PMID  - 37448475
ER  - 

TY  - JOUR
TI  - Automatically annotated motion tracking identifies a distinct social behavioral profile following chronic social defeat stress
AU  - Bordes, Joeri
AU  - Miranda, Lucas
AU  - Reinhardt, Maya
AU  - Narayan, Sowmya
AU  - Hartmann, Jakob
AU  - Newman, Emily L.
AU  - Brix, Lea Maria
AU  - Doeselaar, Lotte van
AU  - Engelhardt, Clara
AU  - Dillmann, Larissa
AU  - Mitra, Shiladitya
AU  - Ressler, Kerry J.
AU  - Pütz, Benno
AU  - Agakov, Felix
AU  - Müller-Myhsok, Bertram
AU  - Schmidt, Mathias V.
T2  - Nature Communications
DO  - 10.1038/s41467-023-40040-3
U1  - 37463994
U2  - PMC10354203
AB  - Severe stress exposure increases the risk of stress-related disorders such as major depressive disorder (MDD). An essential characteristic of MDD is the impairment of social functioning and lack of social motivation. Chronic social defeat stress is an established animal model for MDD research, which induces a cascade of physiological and behavioral changes. Current markerless pose estimation tools allow for more complex and naturalistic behavioral tests. Here, we introduce the open-source tool DeepOF to investigate the individual and social behavioral profile in mice by providing supervised and unsupervised pipelines using DeepLabCut-annotated pose estimation data. Applying this tool to chronic social defeat in male mice, the DeepOF supervised and unsupervised pipelines detect a distinct stress-induced social behavioral pattern, which was particularly observed at the beginning of a novel social encounter and fades with time due to habituation. In addition, while the classical social avoidance task does identify the stress-induced social behavioral differences, both DeepOF behavioral pipelines provide a clearer and more detailed profile. Moreover, DeepOF aims to facilitate reproducibility and unification of behavioral classification by providing an open-source tool, which can advance the study of rodent individual and social behavior, thereby enabling biological insights and, for example, subsequent drug development for psychiatric disorders. Accurate phenotyping is key to deciphering behavior. Here, authors show the utility of the software package DeepOF in supervised and unsupervised identification of distinct individual and social behavioral patterns following chronic social stress.
J2  - Nat. Commun.
SP  - 4319
IS  - 1
VL  - 14
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/a601c74e-372c-488e-af44-83b3acdac7ed
XX  - 
PMID  - 37463994
ER  - 

TY  - JOUR
TI  - Multi-Object Tracking in Heterogeneous environments (MOTHe) for animal video recordings
AU  - Rathore, Akanksha
AU  - Sharma, Ananth
AU  - Shah, Shaan
AU  - Sharma, Nitika
AU  - Torney, Colin
AU  - Guttal, Vishwesha
T2  - PeerJ
DO  - 10.7717/peerj.15573
U1  - 37397020
U2  - PMC10309051
AB  - Aerial imagery and video recordings of animals are used for many areas of research such as animal behaviour, behavioural neuroscience and field biology. Many automated methods are being developed to extract data from such high-resolution videos. Most of the available tools are developed for videos taken under idealised laboratory conditions. Therefore, the task of animal detection and tracking for videos taken in natural settings remains challenging due to heterogeneous environments. Methods that are useful for field conditions are often difficult to implement and thus remain inaccessible to empirical researchers. To address this gap, we present an open-source package called Multi-Object Tracking in Heterogeneous environments (MOTHe), a Python-based application that uses a basic convolutional neural network for object detection. MOTHe offers a graphical interface to automate the various steps related to animal tracking such as training data generation, animal detection in complex backgrounds and visually tracking animals in the videos. Users can also generate training data and train a new model which can be used for object detection tasks for a completely new dataset. MOTHe doesn’t require any sophisticated infrastructure and can be run on basic desktop computing units. We demonstrate MOTHe on six video clips in varying background conditions. These videos are from two species in their natural habitat—wasp colonies on their nests (up to 12 individuals per colony) and antelope herds in four different habitats (up to 156 individuals in a herd). Using MOTHe, we are able to detect and track individuals in all these videos. MOTHe is available as an open-source GitHub repository with a detailed user guide and demonstrations at: https://github.com/tee-lab/MOTHe-GUI.
J2  - PeerJ
SP  - e15573
VL  - 11
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/c647c9c3-6e20-4f27-8747-4690d1888a12
XX  - 
PMID  - 37397020
ER  - 

TY  - JOUR
TI  - Social odor discrimination and its enhancement by associative learning in the hippocampal CA2 region
AU  - Hassan, Sami I.
AU  - Bigler, Shivani
AU  - Siegelbaum, Steven A.
T2  - Neuron
SN  - 0896-6273
DO  - 10.1016/j.neuron.2023.04.026
U1  - 37192623
U2  - PMC10524117
AB  - Although the hippocampus is crucial for social memory, how social sensory information is combined with contextual information to form episodic social memories remains unknown. Here, we investigated the mechanisms for social sensory information processing using two-photon calcium imaging from hippocampal CA2 pyramidal neurons (PNs)—which are crucial for social memory—in awake head-fixed mice exposed to social and non-social odors. We found that CA2 PNs represent social odors of individual conspecifics and that these representations are refined during associative social odor-reward learning to enhance the discrimination of rewarded compared with unrewarded odors. Moreover, the structure of the CA2 PN population activity enables CA2 to generalize along categories of rewarded versus unrewarded and social versus non-social odor stimuli. Finally, we found that CA2 is important for learning social but not non-social odor-reward associations. These properties of CA2 odor representations provide a likely substrate for the encoding of episodic social memory.
J2  - Neuron
SP  - 2232-2246.e5
IS  - 14
VL  - 111
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/0d0d97bd-3a33-4b30-8207-90e02825d295
XX  - 
PMID  - 37192623
ER  - 

TY  - JOUR
TI  - Barrier–environment interactions along the gut–brain axis and their influence on cognition and behaviour throughout the lifespan
AU  - Paton, Sam E.J.
AU  - Solano, José L.
AU  - Coulombe-Rozon, François
AU  - Lebel, Manon
AU  - Menard, Caroline
T2  - Journal of Psychiatry and Neuroscience
SN  - 1180-4882
DO  - 10.1503/jpn.220218
U1  - 37253482
U2  - PMC10234620
AB  - Environment is known to substantially alter mental state and behaviour across the lifespan. Biological barriers such as the blood–brain barrier (BBB) and gut barrier (GB) are major hubs for communication of environmental information. Alterations in the structural, social and motor environment at different stages of life can influence function of the BBB and GB and their integrity to exert behavioural consequences. Importantly, each of these environmental components is associated with a distinct immune profile, glucocorticoid response and gut microbiome composition, creating unique effects on the BBB and GB. These barrier–environment interactions are sensitive to change throughout life, and positive or negative alterations at critical stages of development can exert long-lasting cognitive and behavioural consequences. Furthermore, because loss of barrier integrity is implicated in pathogenesis of mental disorders, the pathways of environmental influence represent important areas for understanding these diseases. Positive environments can be protective against stress- and age-related damage, raising the possibility of novel pharmacological targets. This review summarizes known mechanisms of environmental influence — such as social interactions, structural complexity and physical exercise — on barrier composition, morphology and development, and considers the outcomes and implications of these interactions in the context of psychiatric disorders.
J2  - J. Psychiatry Neurosci.
SP  - E190-E208
IS  - 3
VL  - 48
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/196069a7-bcb1-4562-b110-dd00cabe0b7d
XX  - 
PMID  - 37253482
ER  - 

TY  - JOUR
TI  - Ontogenetic Plasticity in Shoaling Behavior in a Forage Fish under Warming
AU  - Berio, Fidji
AU  - Morerod, Camille
AU  - Qi, Xuewei
AU  - Santo, Valentina Di
T2  - Integrative And Comparative Biology
SN  - 1540-7063
DO  - 10.1093/icb/icad043
U1  - 37245064
U2  - PMC10503471
AB  - Shoaling behavior is known to increase survival rates during attacks from predators, minimize foraging time, favor mating, and potentially increase locomotor efficiency. The onset of shoaling typically occurs during the larval phase, but it is unclear how it may improve across ontogenetic stages in forage fishes. Warming is known to increase metabolic rates during locomotion in solitary fish, and shoaling species may adjust their collective behavior to offset the elevated costs of swimming at higher temperatures. In this study, we quantified the effects of warming on shoaling performance across the ontogeny of a small forage fish, zebrafish (Danio rerio) at different speeds. Shoals of larval, juvenile, and adult zebrafish were acclimated at two temperatures (28°C and 32°C), and metabolic rates were quantified prior to and following nonexhaustive exercise at high speed. Shoals of five individuals were filmed in a flow tank to analyze the kinematics of collective movement. We found that zebrafish improve shoaling swimming performance from larvae to juveniles to adults. In particular, shoals become more cohesive, and both tail beat frequency (TBF) and head-to-tail amplitude decrease with ontogeny. Early life stages have higher thermal sensitivity in metabolic rates and TBF especially at high speeds, when compared to adults. Our study shows that shoaling behavior and thermal sensitivity improve as zebrafish shift from larval to juvenile to adult stages.
J2  - Integr. Comp. Biol.
SP  - 730-741
IS  - 3
VL  - 63
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/1e164488-9ee7-4006-8d56-d790680f74de
XX  - 
PMID  - 37245064
ER  - 

TY  - JOUR
TI  - Robot Programming from Fish Demonstrations
AU  - Coppola, Claudio Massimo
AU  - Strong, James Bradley
AU  - O’Reilly, Lissa
AU  - Dalesman, Sarah
AU  - Akanyeti, Otar
T2  - Biomimetics
DO  - 10.3390/biomimetics8020248
U1  - 37366843
U2  - PMC10296172
AB  - Fish are capable of learning complex relations found in their surroundings, and harnessing their knowledge may help to improve the autonomy and adaptability of robots. Here, we propose a novel learning from demonstration framework to generate fish-inspired robot control programs with as little human intervention as possible. The framework consists of six core modules: (1) task demonstration, (2) fish tracking, (3) analysis of fish trajectories, (4) acquisition of robot training data, (5) generating a perception–action controller, and (6) performance evaluation. We first describe these modules and highlight the key challenges pertaining to each one. We then present an artificial neural network for automatic fish tracking. The network detected fish successfully in 85% of the frames, and in these frames, its average pose estimation error was less than 0.04 body lengths. We finally demonstrate how the framework works through a case study focusing on a cue-based navigation task. Two low-level perception–action controllers were generated through the framework. Their performance was measured using two-dimensional particle simulations and compared against two benchmark controllers, which were programmed manually by a researcher. The fish-inspired controllers had excellent performance when the robot was started from the initial conditions used in fish demonstrations (>96% success rate), outperforming the benchmark controllers by at least 3%. One of them also had an excellent generalisation performance when the robot was started from random initial conditions covering a wider range of starting positions and heading angles (>98% success rate), again outperforming the benchmark controllers by 12%. The positive results highlight the utility of the framework as a research tool to form biological hypotheses on how fish navigate in complex environments and design better robot controllers on the basis of biological findings.
J2  - Biomimetics
SP  - 248
IS  - 2
VL  - 8
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/28fe47bd-54cd-44bf-a802-b5fb7302c994
XX  - 
PMID  - 37366843
ER  - 

TY  - JOUR
TI  - SAMPL is a high-throughput solution to study unconstrained vertical behavior in small animals
AU  - Zhu, Yunlu
AU  - Auer, Franziska
AU  - Gelnaw, Hannah
AU  - Davis, Samantha N.
AU  - Hamling, Kyla R.
AU  - May, Christina E.
AU  - Ahamed, Hassan
AU  - Ringstad, Niels
AU  - Nagel, Katherine I.
AU  - Schoppik, David
T2  - Cell Reports
SN  - 2211-1247
DO  - 10.1016/j.celrep.2023.112573
U1  - 37267107
U2  - PMC10592459
AB  - Balance and movement are impaired in many neurological disorders. Recent advances in behavioral monitoring provide unprecedented access to posture and locomotor kinematics but without the throughput and scalability necessary to screen candidate genes/potential therapeutics. Here, we present a scalable apparatus to measure posture and locomotion (SAMPL). SAMPL includes extensible hardware and open-source software with real-time processing and can acquire data from D. melanogaster, C. elegans, and D. rerio as they move vertically. Using SAMPL, we define how zebrafish balance as they navigate vertically and discover small but systematic variations among kinematic parameters between genetic backgrounds. We demonstrate SAMPL’s ability to resolve differences in posture and navigation as a function of effect size and data gathered, providing key data for screens. SAMPL is therefore both a tool to model balance and locomotor disorders and an exemplar of how to scale apparatus to support screens.
J2  - Cell Rep.
SP  - 112573
IS  - 6
VL  - 42
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/e0886978-75df-441b-ad37-e2f7430e28c2
XX  - 
PMID  - 37267107
ER  - 

TY  - JOUR
TI  - Open-source software for automated rodent behavioral analysis
AU  - Isik, Sena
AU  - Unal, Gunes
T2  - Frontiers in Neuroscience
SN  - 1662-4548
DO  - 10.3389/fnins.2023.1149027
U1  - 37139530
U2  - PMC10149747
AB  - Rodent behavioral analysis is a major specialization in experimental psychology and behavioral neuroscience. Rodents display a wide range of species-specific behaviors, not only in their natural habitats but also under behavioral testing in controlled laboratory conditions. Detecting and categorizing these different kinds of behavior in a consistent way is a challenging task. Observing and analyzing rodent behaviors manually limits the reproducibility and replicability of the analyses due to potentially low inter-rater reliability. The advancement and accessibility of object tracking and pose estimation technologies led to several open-source artificial intelligence (AI) tools that utilize various algorithms for rodent behavioral analysis. These software provide high consistency compared to manual methods, and offer more flexibility than commercial systems by allowing custom-purpose modifications for specific research needs. Open-source software reviewed in this paper offer automated or semi-automated methods for detecting and categorizing rodent behaviors by using hand-coded heuristics, machine learning, or neural networks. The underlying algorithms show key differences in their internal dynamics, interfaces, user-friendliness, and the variety of their outputs. This work reviews the algorithms, capability, functionality, features and software properties of open-source behavioral analysis tools, and discusses how this emergent technology facilitates behavioral quantification in rodent research.
J2  - Front. Neurosci.
SP  - 1149027
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/2f8c357a-b454-437e-9af6-f1e7e9eba388
XX  - 
PMID  - 37139530
ER  - 

TY  - JOUR
TI  - Lightning Pose: improved animal pose estimation via semi-supervised learning, Bayesian ensembling, and cloud-native open-source tools
AU  - Biderman, Dan
AU  - Whiteway, Matthew R
AU  - Hurwitz, Cole
AU  - Greenspan, Nicholas
AU  - Lee, Robert S
AU  - Vishnubhotla, Ankit
AU  - Warren, Richard
AU  - Pedraja, Federico
AU  - Noone, Dillon
AU  - Schartner, Michael
AU  - Huntenburg, Julia M
AU  - Khanal, Anup
AU  - Meijer, Guido T
AU  - Noel, Jean-Paul
AU  - Pan-Vazquez, Alejandro
AU  - Socha, Karolina Z
AU  - Urai, Anne E
AU  - Laboratory, The International Brain
AU  - Cunningham, John P
AU  - Sawtell, Nathaniel
AU  - Paninski, Liam
T2  - bioRxiv
DO  - 10.1101/2023.04.28.538703
U1  - 37162966
U2  - PMC10168383
AB  - Pose estimation algorithms are shedding new light on animal behavior and intelligence. Most existing models are only trained with labeled frames (supervised learning). Although effective in many cases, the fully supervised approach requires extensive image labeling, struggles to generalize to new videos, and produces noisy outputs that hinder downstream analyses. We address each of these limitations with a semi-supervised approach that leverages the spatiotemporal statistics of unlabeled videos in two different ways. First, we introduce unsupervised training objectives that penalize the network whenever its predictions violate smoothness of physical motion, multiple-view geometry, or depart from a low-dimensional subspace of plausible body configurations. Second, we design a new network architecture that predicts pose for a given frame using temporal context from surrounding unlabeled frames. These context frames help resolve brief occlusions or ambiguities between nearby and similar-looking body parts. The resulting pose estimation networks achieve better performance with fewer labels, generalize better to unseen videos, and provide smoother and more reliable pose trajectories for downstream analysis; for example, these improved pose trajectories exhibit stronger correlations with neural activity. We also propose a Bayesian post-processing approach based on deep ensembling and Kalman smoothing that further improves tracking accuracy and robustness. We release a deep learning package that adheres to industry best practices, supporting easy model development and accelerated training and prediction. Our package is accompanied by a cloud application that allows users to annotate data, train networks, and predict new videos at scale, directly from the browser.
J2  - bioRxiv
SP  - 2023.04.28.538703
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/8833c304-3774-447a-98b2-fa7316dc2bb9
XX  - 
PMID  - 37162966
ER  - 

TY  - JOUR
TI  - PyMouseTracks: Flexible Computer Vision and RFID-Based System for Multiple Mouse Tracking and Behavioral Assessment
AU  - Fong, Tony
AU  - Hu, Hao
AU  - Gupta, Pankaj
AU  - Jury, Braeden
AU  - Murphy, Timothy H.
T2  - eNeuro
DO  - 10.1523/eneuro.0127-22.2023
U1  - 37185293
U2  - PMC10198609
AB  - PyMouseTracks (PMT) is a scalable and customizable computer vision and radio frequency identification (RFID)-based system for multiple rodent tracking and behavior assessment that can be set up within minutes in any user-defined arena at minimal cost. PMT is composed of the online Raspberry Pi (RPi)-based video and RFID acquisition with subsequent offline analysis tools. The system is capable of tracking up to six mice in experiments ranging from minutes to days. PMT maintained a minimum of 88% detections tracked with an overall accuracy >85% when compared with manual validation of videos containing one to four mice in a modified home-cage. As expected, chronic recording in home-cage revealed diurnal activity patterns. In open-field, it was observed that novel noncagemate mouse pairs exhibit more similarity in travel trajectory patterns than cagemate pairs over a 10-min period. Therefore, shared features within travel trajectories between animals may be a measure of sociability that has not been previously reported. Moreover, PMT can interface with open-source packages such as DeepLabCut and Traja for pose estimation and travel trajectory analysis, respectively. In combination with Traja, PMT resolved motor deficits exhibited in stroke animals. Overall, we present an affordable, open-sourced, and customizable/scalable mouse behavior recording and analysis system.
J2  - eNeuro
SP  - ENEURO.0127-22.2023
IS  - 5
VL  - 10
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/9212062d-ae2d-4c11-a80b-219e4d07a4f5
XX  - 
PMID  - 37185293
ER  - 

TY  - JOUR
TI  - CATER: Combined Animal Tracking & Environment Reconstruction
AU  - Haalck, Lars
AU  - Mangan, Michael
AU  - Wystrach, Antoine
AU  - Clement, Leo
AU  - Webb, Barbara
AU  - Risse, Benjamin
T2  - Science Advances
DO  - 10.1126/sciadv.adg2094
U1  - 37083522
U2  - PMC10121171
AB  - Quantifying the behavior of small animals traversing long distances in complex environments is one of the most difficult tracking scenarios for computer vision. Tiny and low-contrast foreground objects have to be localized in cluttered and dynamic scenes as well as trajectories compensated for camera motion and drift in multiple lengthy recordings. We introduce CATER, a novel methodology combining an unsupervised probabilistic detection mechanism with a globally optimized environment reconstruction pipeline enabling precision behavioral quantification in natural environments. Implemented as an easy to use and highly parallelized tool, we show its application to recover fine-scale motion trajectories, registered to a high-resolution image mosaic reconstruction, of naturally foraging desert ants from unconstrained field recordings. By bridging the gap between laboratory and field experiments, we gain previously unknown insights into ant navigation with respect to motivational states, previous experience, and current environments and provide an appearance-agnostic method applicable to study the behavior of a wide range of terrestrial species under realistic conditions.
J2  - Sci. Adv.
SP  - eadg2094
IS  - 16
VL  - 9
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/ef5bbb29-57d9-4b9c-bfac-454137a58dc7
XX  - 
PMID  - 37083522
ER  - 

TY  - JOUR
TI  - Copy number variation in tRNA isodecoder genes impairs mammalian development and balanced translation
AU  - Hughes, Laetitia A.
AU  - Rudler, Danielle L.
AU  - Siira, Stefan J.
AU  - McCubbin, Tim
AU  - Raven, Samuel A.
AU  - Browne, Jasmin M.
AU  - Ermer, Judith A.
AU  - Rientjes, Jeanette
AU  - Rodger, Jennifer
AU  - Marcellin, Esteban
AU  - Rackham, Oliver
AU  - Filipovska, Aleksandra
T2  - Nature Communications
DO  - 10.1038/s41467-023-37843-9
U1  - 37072429
U2  - PMC10113395
AB  - The number of tRNA isodecoders has increased dramatically in mammals, but the specific molecular and physiological reasons for this expansion remain elusive. To address this fundamental question we used CRISPR editing to knockout the seven-membered phenylalanine tRNA gene family in mice, both individually and combinatorially. Using ATAC-Seq, RNA-seq, ribo-profiling and proteomics we observed distinct molecular consequences of single tRNA deletions. We show that tRNA-Phe-1-1 is required for neuronal function and its loss is partially compensated by increased expression of other tRNAs but results in mistranslation. In contrast, the other tRNA-Phe isodecoder genes buffer the loss of each of the remaining six tRNA-Phe genes. In the tRNA-Phe gene family, the expression of at least six tRNA-Phe alleles is required for embryonic viability and tRNA-Phe-1-1 is most important for development and survival. Our results reveal that the multi-copy configuration of tRNA genes is required to buffer translation and viability in mammals. Enigmatically tRNA genes exist in several hundred copies in mammalian genomes. Here the authors find a precipitous failure of development and increased amino acid misincorporation upon systematic elimination of tRNA-Phe genes in mice using CRISPR.
J2  - Nat. Commun.
SP  - 2210
IS  - 1
VL  - 14
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/74c9b302-b68a-40b1-923b-abbd57e0230a
XX  - 
PMID  - 37072429
ER  - 

TY  - JOUR
TI  - Leptin deficiency-caused behavioral change – A comparative analysis using EthoVision and DeepLabCut
AU  - Bühler, Daniel
AU  - Guerra, Nicole Power
AU  - Müller, Luisa
AU  - Wolkenhauer, Olaf
AU  - Düffer, Martin
AU  - Vollmar, Brigitte
AU  - Kuhla, Angela
AU  - Wolfien, Markus
T2  - Frontiers in Neuroscience
SN  - 1662-4548
DO  - 10.3389/fnins.2023.1052079
U1  - 37034162
U2  - PMC10079875
AB  - Obese rodents e.g., the leptin-deficient (ob/ob) mouse exhibit remarkable behavioral changes and are therefore ideal models for evaluating mental disorders resulting from obesity. In doing so, female as well as male ob/ob mice at 8, 24, and 40 weeks of age underwent two common behavioral tests, namely the Open Field test and Elevated Plus Maze, to investigate behavioral alteration in a sex- and age dependent manner. The accuracy of these tests is often dependent on the observer that can subjectively influence the data. To avoid this bias, mice were tracked with a video system. Video files were further analyzed by the compared use of two software, namely EthoVision (EV) and DeepLabCut (DLC). In DLC a Deep Learning application forms the basis for using artificial intelligence in behavioral research in the future, also with regard to the reduction of animal numbers. After no sex and partly also no age-related differences were found, comparison revealed that both software lead to almost identical results and are therefore similar in their basic outcomes, especially in the determination of velocity and total distance movement. Moreover, we observed additional benefits of DLC compared to EV as it enabled the interpretation of more complex behavior, such as rearing and leaning, in an automated manner. Based on the comparable results from both software, our study can serve as a starting point for investigating behavioral alterations in preclinical studies of obesity by using DLC to optimize and probably to predict behavioral observations in the future.
J2  - Front. Neurosci.
SP  - 1052079
VL  - 17
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/e3dcd2f0-c85a-45d8-8db4-e68116eb7066
XX  - 
PMID  - 37034162
ER  - 

TY  - JOUR
TI  - Open-source tools for behavioral video analysis: Setup, methods, and best practices
AU  - Luxem, Kevin
AU  - Sun, Jennifer J
AU  - Bradley, Sean P
AU  - Krishnan, Keerthi
AU  - Yttri, Eric
AU  - Zimmermann, Jan
AU  - Pereira, Talmo D
AU  - Laubach, Mark
T2  - eLife
DO  - 10.7554/elife.79305
U1  - 36951911
U2  - PMC10036114
AB  - Recently developed methods for video analysis, especially models for pose estimation and behavior classification, are transforming behavioral quantification to be more precise, scalable, and reproducible in fields such as neuroscience and ethology. These tools overcome long-standing limitations of manual scoring of video frames and traditional ‘center of mass’ tracking algorithms to enable video analysis at scale. The expansion of open-source tools for video acquisition and analysis has led to new experimental approaches to understand behavior. Here, we review currently available open-source tools for video analysis and discuss how to set up these methods for labs new to video recording. We also discuss best practices for developing and using video analysis methods, including community-wide standards and critical needs for the open sharing of datasets and code, more widespread comparisons of video analysis methods, and better documentation for these methods especially for new users. We encourage broader adoption and continued development of these tools, which have tremendous potential for accelerating scientific progress in understanding the brain and behavior.
J2  - eLife
SP  - e79305
VL  - 12
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/522ad29a-cdb8-4654-b783-814ce95b5445
XX  - 
PMID  - 36951911
ER  - 

TY  - JOUR
TI  - Associative learning in the cnidarian Nematostella vectensis
AU  - Botton-Amiot, Gaelle
AU  - Martinez, Pedro
AU  - Sprecher, Simon G.
T2  - Proceedings of the National Academy of Sciences
SN  - 0027-8424
DO  - 10.1073/pnas.2220685120
U1  - 36940325
U2  - PMC10068830
AB  - The ability to learn and form memories allows animals to adapt their behavior based on previous experiences. Associative learning, the process through which organisms learn about the relationship between two distinct events, has been extensively studied in various animal taxa. However, the existence of associative learning, prior to the emergence of centralized nervous systems in bilaterian animals, remains unclear. Cnidarians such as sea anemones or jellyfish possess a nerve net, which lacks centralization. As the sister group to bilaterians, they are particularly well suited for studying the evolution of nervous system functions. Here, we probe the capacity of the starlet sea anemone Nematostella vectensis to form associative memories by using a classical conditioning approach. We developed a protocol combining light as the conditioned stimulus with an electric shock as the aversive unconditioned stimulus. After repetitive training, animals exhibited a conditioned response to light alone—indicating that they learned the association. In contrast, all control conditions did not form associative memories. Besides shedding light on an aspect of cnidarian behavior, these results root associative learning before the emergence of NS centralization in the metazoan lineage and raise fundamental questions about the origin and evolution of cognition in brainless animals.
J2  - Proc. Natl. Acad. Sci.
SP  - e2220685120
IS  - 13
VL  - 120
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/bf8f696a-a29d-4f4a-b13f-30253c3b6142
XX  - 
PMID  - 36940325
ER  - 

TY  - JOUR
TI  - Using pose estimation to identify regions and points on natural history specimens
AU  - He, Yichen
AU  - Cooney, Christopher R
AU  - Maddock, Steve
AU  - Thomas, Gavin H
T2  - PLOS Computational Biology
DO  - 10.1371/journal.pcbi.1010933
U1  - 36812227
U2  - PMC9987800
AB  - A key challenge in mobilising growing numbers of digitised biological specimens for scientific research is finding high-throughput methods to extract phenotypic measurements on these datasets. In this paper, we test a pose estimation approach based on Deep Learning capable of accurately placing point labels to identify key locations on specimen images. We then apply the approach to two distinct challenges that each requires identification of key features in a 2D image: (i) identifying body region-specific plumage colouration on avian specimens and (ii) measuring morphometric shape variation in Littorina snail shells. For the avian dataset, 95% of images are correctly labelled and colour measurements derived from these predicted points are highly correlated with human-based measurements. For the Littorina dataset, more than 95% of landmarks were accurately placed relative to expert-labelled landmarks and predicted landmarks reliably captured shape variation between two distinct shell ecotypes (‘crab’ vs ‘wave’). Overall, our study shows that pose estimation based on Deep Learning can generate high-quality and high-throughput point-based measurements for digitised image-based biodiversity datasets and could mark a step change in the mobilisation of such data. We also provide general guidelines for using pose estimation methods on large-scale biological datasets.
J2  - PLOS Comput. Biol.
SP  - e1010933
IS  - 2
VL  - 19
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/4c23f1d8-0f60-4d8a-94b3-ec359236655f
XX  - 
PMID  - 36812227
ER  - 

TY  - JOUR
TI  - Leveraging big data to uncover the eco-evolutionary factors shaping behavioural development
AU  - Ehlman, Sean M.
AU  - Scherer, Ulrike
AU  - Bierbach, David
AU  - Francisco, Fritz A.
AU  - Laskowski, Kate L.
AU  - Krause, Jens
AU  - Wolf, Max
T2  - Proceedings of the Royal Society B
SN  - 0962-8452
DO  - 10.1098/rspb.2022.2115
U1  - 36722081
U2  - PMC9890127
AB  - Mapping the eco-evolutionary factors shaping the development of animals’ behavioural phenotypes remains a great challenge. Recent advances in ‘big behavioural data’ research—the high-resolution tracking of individuals and the harnessing of that data with powerful analytical tools—have vastly improved our ability to measure and model developing behavioural phenotypes. Applied to the study of behavioural ontogeny, the unfolding of whole behavioural repertoires can be mapped in unprecedented detail with relative ease. This overcomes long-standing experimental bottlenecks and heralds a surge of studies that more finely define and explore behavioural–experiential trajectories across development. In this review, we first provide a brief guide to state-of-the-art approaches that allow the collection and analysis of high-resolution behavioural data across development. We then outline how such approaches can be used to address key issues regarding the ecological and evolutionary factors shaping behavioural development: developmental feedbacks between behaviour and underlying states, early life effects and behavioural transitions, and information integration across development.
J2  - Proc. R. Soc. B
SP  - 20222115
IS  - 1992
VL  - 290
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/95b5c94e-42e8-439d-bc99-82a814b5c7fc
XX  - 
PMID  - 36722081
ER  - 

TY  - JOUR
TI  - Three-dimensional unsupervised probabilistic pose reconstruction (3D-UPPER) for freely moving animals
AU  - Ebrahimi, Aghileh S.
AU  - Orlowska-Feuer, Patrycja
AU  - Huang, Qian
AU  - Zippo, Antonio G.
AU  - Martial, Franck P.
AU  - Petersen, Rasmus S.
AU  - Storchi, Riccardo
T2  - Scientific Reports
DO  - 10.1038/s41598-022-25087-4
U1  - 36599877
U2  - PMC9813182
AB  - A key step in understanding animal behaviour relies in the ability to quantify poses and movements. Methods to track body landmarks in 2D have made great progress over the last few years but accurate 3D reconstruction of freely moving animals still represents a challenge. To address this challenge here we develop the 3D-UPPER algorithm, which is fully automated, requires no a priori knowledge of the properties of the body and can also be applied to 2D data. We find that 3D-UPPER reduces by >10 fold the error in 3D reconstruction of mouse body during freely moving behaviour compared with the traditional triangulation of 2D data. To achieve that, 3D-UPPER performs an unsupervised estimation of a Statistical Shape Model (SSM) and uses this model to constrain the viable 3D coordinates. We show, by using simulated data, that our SSM estimator is robust even in datasets containing up to 50% of poses with outliers and/or missing data. In simulated and real data SSM estimation converges rapidly, capturing behaviourally relevant changes in body shape associated with exploratory behaviours (e.g. with rearing and changes in body orientation). Altogether 3D-UPPER represents a simple tool to minimise errors in 3D reconstruction while capturing meaningful behavioural parameters.
J2  - Sci. Rep.
SP  - 155
IS  - 1
VL  - 13
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/8c0e8843-f463-43de-8c43-7eb86fd410a0
XX  - 
PMID  - 36599877
ER  - 

TY  - JOUR
TI  - Marker-less tracking system for multiple mice using Mask R-CNN
AU  - Sakamoto, Naoaki
AU  - Kakeno, Hitoshi
AU  - Ozaki, Noriko
AU  - Miyazaki, Yusuke
AU  - Kobayashi, Koji
AU  - Murata, Takahisa
T2  - Frontiers in Behavioral Neuroscience
SN  - 1662-5153
DO  - 10.3389/fnbeh.2022.1086242
U1  - 36688129
U2  - PMC9853548
AB  - Although the appropriate evaluation of mouse behavior is crucial in pharmacological research, most current methods focus on single mouse behavior under light conditions, owing to the limitations of human observation and experimental tools. In this study, we aimed to develop a novel marker-less tracking method for multiple mice with top-view videos using deep-learning-based techniques. The following stepwise method was introduced: (i) detection of mouse contours, (ii) assignment of identifiers (IDs) to each mouse, and (iii) correction of mis-predictions. The behavior of C57BL/6 mice was recorded in an open-field arena, and the mouse contours were manually annotated for hundreds of frame images. Then, we trained the mask regional convolutional neural network (Mask R-CNN) with all annotated images. The mouse contours predicted by the trained model in each frame were assigned to IDs by calculating the similarities of every mouse pair between frames. After assigning IDs, correction steps were applied to remove the predictive errors semi-automatically. The established method could accurately predict two to four mice for first-look videos recorded under light conditions. The method could also be applied to videos recorded under dark conditions, extending our ability to accurately observe and analyze the sociality of nocturnal mice. This technology would enable a new approach to understand mouse sociality and advance the pharmacological research.
J2  - Front. Behav. Neurosci.
SP  - 1086242
VL  - 16
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/b1f7915c-5228-4cd7-b04d-bf007406ea15
XX  - 
PMID  - 36688129
ER  - 

TY  - JOUR
TI  - Scalable Apparatus to Measure Posture and Locomotion (SAMPL): a high-throughput solution to study unconstrained vertical behavior in small animals
AU  - Zhu, Yunlu
AU  - Auer, Franziska
AU  - Gelnaw, Hannah
AU  - Davis, Samantha N.
AU  - Hamling, Kyla R.
AU  - May, Christina E.
AU  - Ahamed, Hassan
AU  - Ringstad, Niels
AU  - Nagel, Katherine I.
AU  - Schoppik, David
T2  - bioRxiv
DO  - 10.1101/2023.01.07.523102
U1  - 36712122
U2  - PMC9881893
AB  - Balance and movement are impaired in a wide variety of neurological disorders. Recent advances in behavioral monitoring provide unprecedented access to posture and loco-motor kinematics, but without the throughput and scalability necessary to screen candidate genes / potential therapeutics. We present a powerful solution: a Scalable Apparatus to Measure Posture and Locomotion (SAMPL). SAMPL includes extensible imaging hardware and low-cost open-source acquisition software with real-time processing. We first demonstrate that SAMPL’s hardware and acquisition software can acquire data from D. melanogaster, C.elegans, and D. rerio as they move vertically. Next, we leverage SAMPL’s throughput to rapidly (two weeks) gather a new zebrafish dataset. We use SAMPL’s analysis and visualization tools to replicate and extend our current understanding of how zebrafish balance as they navigate through a vertical environment. Next, we discover (1) that key kinematic parameters vary systematically with genetic background, and (2) that such background variation is small relative to the changes that accompany early development. Finally, we simulate SAMPL’s ability to resolve differences in posture or vertical navigation as a function of effect size and data gathered – key data for screens. Taken together, our apparatus, data, and analysis provide a powerful solution for laboratories using small animals to investigate balance and locomotor disorders at scale. More broadly, SAMPL is both an adaptable resource for laboratories looking process video-graphic measures of behavior in real-time, and an exemplar of how to scale hardware to enable the throughput necessary for screening.
J2  - bioRxiv
SP  - 2023.01.07.523102
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/fc42efa2-e82a-49ff-920c-482a40912914
XX  - 
PMID  - 36712122
ER  - 

TY  - JOUR
TI  - Noninvasive Tracking of Every Individual in Unmarked Mouse Groups Using Multi-Camera Fusion and Deep Learning
AU  - Su, Feng
AU  - Wang, Yangzhen
AU  - Wei, Mengping
AU  - Wang, Chong
AU  - Wang, Shaoli
AU  - Yang, Lei
AU  - Li, Jianmin
AU  - Yuan, Peijiang
AU  - Luo, Dong-Gen
AU  - Zhang, Chen
T2  - Neuroscience Bulletin
SN  - 1673-7067
DO  - 10.1007/s12264-022-00988-6
U1  - 36571715
U2  - PMC10264345
AB  - Accurate and efficient methods for identifying and tracking each animal in a group are needed to study complex behaviors and social interactions. Traditional tracking methods (e.g., marking each animal with dye or surgically implanting microchips) can be invasive and may have an impact on the social behavior being measured. To overcome these shortcomings, video-based methods for tracking unmarked animals, such as fruit flies and zebrafish, have been developed. However, tracking individual mice in a group remains a challenging problem because of their flexible body and complicated interaction patterns. In this study, we report the development of a multi-object tracker for mice that uses the Faster region-based convolutional neural network (R-CNN) deep learning algorithm with geometric transformations in combination with multi-camera/multi-image fusion technology. The system successfully tracked every individual in groups of unmarked mice and was applied to investigate chasing behavior. The proposed system constitutes a step forward in the noninvasive tracking of individual mice engaged in social behavior.
J2  - Neurosci. Bull.
SP  - 893-910
IS  - 6
VL  - 39
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/aedbc39a-b10e-492b-a54a-3354282af363
XX  - 
PMID  - 36571715
ER  - 

TY  - JOUR
TI  - Using deep learning to study emotional behavior in rodent models
AU  - Kuo, Jessica Y.
AU  - Denman, Alexander J.
AU  - Beacher, Nicholas J.
AU  - Glanzberg, Joseph T.
AU  - Zhang, Yan
AU  - Li, Yun
AU  - Lin, Da-Ting
T2  - Frontiers in Behavioral Neuroscience
SN  - 1662-5153
DO  - 10.3389/fnbeh.2022.1044492
U1  - 36483523
U2  - PMC9722968
AB  - Quantifying emotional aspects of animal behavior (e.g., anxiety, social interactions, reward, and stress responses) is a major focus of neuroscience research. Because manual scoring of emotion-related behaviors is time-consuming and subjective, classical methods rely on easily quantified measures such as lever pressing or time spent in different zones of an apparatus (e.g., open vs. closed arms of an elevated plus maze). Recent advancements have made it easier to extract pose information from videos, and multiple approaches for extracting nuanced information about behavioral states from pose estimation data have been proposed. These include supervised, unsupervised, and self-supervised approaches, employing a variety of different model types. Representations of behavioral states derived from these methods can be correlated with recordings of neural activity to increase the scope of connections that can be drawn between the brain and behavior. In this mini review, we will discuss how deep learning techniques can be used in behavioral experiments and how different model architectures and training paradigms influence the type of representation that can be obtained.
J2  - Front. Behav. Neurosci.
SP  - 1044492
VL  - 16
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/ed225a29-7e55-4c65-9e9e-c8a554028d0a
XX  - 
PMID  - 36483523
ER  - 

TY  - JOUR
TI  - “Natural Laboratory Complex” for novel primate neuroscience
AU  - Iriki, Atsushi
AU  - Tramacere, Antonella
T2  - Frontiers in Integrative Neuroscience
SN  - 1662-5145
DO  - 10.3389/fnint.2022.927605
U1  - 36274659
U2  - PMC9581230
AB  - We propose novel strategies for primate experimentation that are ethically valuable and pragmatically useful for cognitive neuroscience and neuropsychiatric research. Specifically, we propose Natural Laboratory Complex or Natural Labs, which are a combination of indoor-outdoor structures for studying free moving and socially housed primates in natural or naturalistic environment. We contend that Natural Labs are pivotal to improve primate welfare, and at the same time to implement longitudinal and socio-ecological studies of primate brain and behavior. Currently emerging advanced technologies and social systems (including recent COVID-19 induced “remote” infrastructures) can speed-up cognitive neuroscience approaches in freely behaving animals. Experimental approaches in natural(istic) settings are not in competition with conventional approaches of laboratory investigations, and could establish several benefits at the ethical, experimental, and economic levels.
J2  - Front. Integr. Neurosci.
SP  - 927605
VL  - 16
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/d9f71c4a-d4f9-406c-b8d3-85dca3392160
XX  - 
PMID  - 36274659
ER  - 

TY  - JOUR
TI  - Suppressed prefrontal neuronal firing variability and impaired social representation in IRSp53-mutant mice
AU  - Kim, Woohyun
AU  - Shin, Jae Jin
AU  - Jeong, Yu Jin
AU  - Kim, Kyungdeok
AU  - Bae, Jung Won
AU  - Noh, Young Woo
AU  - Lee, Seungjoon
AU  - Choi, Woochul
AU  - Paik, Se-Bum
AU  - Jung, Min Whan
AU  - Lee, Eunee
AU  - Kim, Eunjoon
T2  - eLife
DO  - 10.7554/elife.74998
U1  - 36317872
U2  - PMC9662818
AB  - Social deficit is a major feature of neuropsychiatric disorders, including autism spectrum disorders, schizophrenia, and attention-deficit/hyperactivity disorder, but its neural mechanisms remain unclear. Here, we examined neuronal discharge characteristics in the medial prefrontal cortex (mPFC) of IRSp53/Baiap2-mutant mice, which show social deficits, during social approach. We found a decrease in the proportion of IRSp53-mutant excitatory mPFC neurons encoding social information, but not that encoding non-social information. In addition, the firing activity of IRSp53-mutant neurons was less differential between social and non-social targets. IRSp53-mutant excitatory mPFC neurons displayed an increase in baseline neuronal firing, but decreases in the variability and dynamic range of firing as well as burst firing during social and non-social target approaches compared to wild-type controls. Treatment of memantine, an NMDA receptor antagonist that rescues social deficit in IRSp53-mutant mice, alleviates the reduced burst firing of IRSp53-mutant pyramidal mPFC neurons. These results suggest that suppressed neuronal activity dynamics and burst firing may underlie impaired cortical encoding of social information and social behaviors in IRSp53-mutant mice.
J2  - eLife
VL  - 11
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/e64a7788-1099-4a1a-96e1-a4d9b97d4114
XX  - 
PMID  - 36317872
ER  - 

TY  - JOUR
TI  - Behaviour Real-Time Spatial Tracking Identification (BeRSTID) used for Cat Behaviour Monitoring in an Animal Shelter
AU  - Eagan, B. H.
AU  - Eagan, B.
AU  - Protopopova, A.
T2  - Scientific Reports
DO  - 10.1038/s41598-022-22167-3
U1  - 36266417
U2  - PMC9584257
AB  - Efficiently tracking animal behaviour in an animal shelter has direct lifesaving applications. Individualized care and early recognition of distress in cats are often missed. However, monitoring behaviour is a challenge as time and financial resources are often limited, and the size and needs of animal populations within shelters are commonly in flux. Our research required a method of behavioural observation that was simple, accessible, used limited human and computer resources and allowed for real-time feedback. Here, we present BeRSTID, an open-source behaviour real-time spatial tracking identification system demonstrated on six cats in an animal shelter using unique 2D fiducial markers. The markers were attached to custom veterinary paper identification collars for feedback on individual animal behaviour over time. Our findings show that BeRSTID correlated closely to human-coded data in both real-time and post-event processing modes of eating and drinking behaviours of cats in naturalistic shelter environments. By building upon a lateral concept of marker tracking for direct applied use in a new context, we present a low-barrier user-friendly solution using common technologies that can track animals for research and, with further development, may help improve welfare in animal care facilities such as shelters. Extensions of BeRSTID may be generalized to track unique subjects in varied environments for multiple use cases.
J2  - Sci. Rep.
SP  - 17585
IS  - 1
VL  - 12
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/a2bcc633-748e-4ffb-8afc-89229bed06e0
XX  - 
PMID  - 36266417
ER  - 

TY  - JOUR
TI  - Towards the fully automated monitoring of ecological communities
AU  - Besson, Marc
AU  - Alison, Jamie
AU  - Bjerge, Kim
AU  - Gorochowski, Thomas E.
AU  - Høye, Toke T.
AU  - Jucker, Tommaso
AU  - Mann, Hjalte M. R.
AU  - Clements, Christopher F.
T2  - Ecology Letters
SN  - 1461-023X
DO  - 10.1111/ele.14123
U1  - 36264848
U2  - PMC9828790
AB  - High‐resolution monitoring is fundamental to understand ecosystems dynamics in an era of global change and biodiversity declines. While real‐time and automated monitoring of abiotic components has been possible for some time, monitoring biotic components—for example, individual behaviours and traits, and species abundance and distribution—is far more challenging. Recent technological advancements offer potential solutions to achieve this through: (i) increasingly affordable high‐throughput recording hardware, which can collect rich multidimensional data, and (ii) increasingly accessible artificial intelligence approaches, which can extract ecological knowledge from large datasets. However, automating the monitoring of facets of ecological communities via such technologies has primarily been achieved at low spatiotemporal resolutions within limited steps of the monitoring workflow. Here, we review existing technologies for data recording and processing that enable automated monitoring of ecological communities. We then present novel frameworks that combine such technologies, forming fully automated pipelines to detect, track, classify and count multiple species, and record behavioural and morphological traits, at resolutions which have previously been impossible to achieve. Based on these rapidly developing technologies, we illustrate a solution to one of the greatest challenges in ecology: the ability to rapidly generate high‐resolution, multidimensional and standardised data across complex ecologies. Monitoring living organisms with high‐resolution and multidimensional is a complex and labour‐intensive task, yet it is fundamental to understand and predict the dynamics of ecological communities in an era of global change and biodiversity declines. Here, we review existing technologies for automated data recording and processing, and we present novel frameworks that combine these technologies into automated monitoring pipelines that detect, track, classify and count multiple species, and even record behavioural and morphological traits at resolutions which have previously been impossible to achieve. We illustrate a solution to one of the greatest challenges in ecology and conservation: the ability to rapidly generate high resolution, multidimensional and critically, standardised data across complex ecologies.
J2  - Ecol. Lett.
SP  - 2753-2775
IS  - 12
VL  - 25
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/b81b8778-8184-4f0c-871c-cff96291e7c0
XX  - 
PMID  - 36264848
ER  - 

TY  - JOUR
TI  - A virtual library for behavioral performance in standard conditions—rodent spontaneous activity in an open field during repeated testing and after treatment with drugs or brain lesions
AU  - Szechtman, Henry
AU  - Dvorkin-Gheva, Anna
AU  - Gomez-Marin, Alex
T2  - GigaScience
DO  - 10.1093/gigascience/giac092
U1  - 36261217
U2  - PMC9581716
AB  - Beyond their specific experiment, video records of behavior have future value—for example, as inputs for new experiments or for yet unknown types of analysis of behavior—similar to tissue or blood sample banks in life sciences where clinically derived or otherwise well-described experimental samples are stored to be available for some unknown potential future purpose. Research using an animal model of obsessive-compulsive disorder employed a standardized paradigm where the behavior of rats in a large open field was video recorded for 55 minutes on each test. From 43 experiments, there are 19,976 such trials that amount to over 2 years of continuous recording. In addition to videos, there are 2 video-derived raw data objects: XY locomotion coordinates and plots of animal trajectory. To motivate future use, the 3 raw data objects are annotated with a general schema—one that abstracts the data records from their particular experiment while providing, at the same time, a detailed list of independent variables bearing on behavioral performance. The raw data objects are deposited as 43 datasets but constitute, functionally, a library containing 1 large dataset. Size and annotation schema give the library high reuse potential: in applications using machine learning techniques, statistical evaluation of subtle factors, simulation of new experiments, or as educational resource. Ultimately, the library can serve both as the seed and as the test bed to create a machine-searchable virtual library of linked open datasets for behavioral performance in defined conditions.
J2  - GigaScience
SP  - giac092
VL  - 11
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/adf0b36b-2f0d-44aa-86c4-4504adafb0d2
XX  - 
PMID  - 36261217
ER  - 

TY  - JOUR
TI  - Machine learning and deep learning frameworks for the automated analysis of pain and opioid withdrawal behaviors
AU  - Bumgarner, Jacob R.
AU  - Becker-Krail, Darius D.
AU  - White, Rhett C.
AU  - Nelson, Randy J.
T2  - Frontiers in Neuroscience
SN  - 1662-4548
DO  - 10.3389/fnins.2022.953182
U1  - 36225736
U2  - PMC9549170
AB  - The automation of behavioral tracking and analysis in preclinical research can serve to advance the rate of research outcomes, increase experimental scalability, and challenge the scientific reproducibility crisis. Recent advances in the efficiency, accuracy, and accessibility of deep learning (DL) and machine learning (ML) frameworks are enabling this automation. As the ongoing opioid epidemic continues to worsen alongside increasing rates of chronic pain, there are ever-growing needs to understand opioid use disorders (OUDs) and identify non-opioid therapeutic options for pain. In this review, we examine how these related needs can be advanced by the development and validation of DL and ML resources for automated pain and withdrawal behavioral tracking. We aim to emphasize the utility of these tools for automated behavioral analysis, and we argue that currently developed models should be deployed to address novel questions in the fields of pain and OUD research.
J2  - Front. Neurosci.
SP  - 953182
VL  - 16
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/c039ff9a-b601-442d-9337-703cadd5b52f
XX  - 
PMID  - 36225736
ER  - 

TY  - JOUR
TI  - Using DeepLabCut as a Real-Time and Markerless Tool for Cardiac Physiology Assessment in Zebrafish
AU  - Suryanto, Michael Edbert
AU  - Saputra, Ferry
AU  - Kurnia, Kevin Adi
AU  - Vasquez, Ross D.
AU  - Roldan, Marri Jmelou M.
AU  - Chen, Kelvin H.-C.
AU  - Huang, Jong-Chin
AU  - Hsiao, Chung-Der
T2  - Biology
SN  - 2079-7737
DO  - 10.3390/biology11081243
U1  - 36009871
U2  - PMC9405297
AB  - With the advancement of existing technology, artificial intelligence is widely applied in various fields of research, including cardiovascular studies. In this study, we explored the feasibility of conducting a markerless cardiac physiology assessment in zebrafish embryos by using DeepLabCut (DLC), a deep learning tool for motion analysis. Several cardiac parameters, such as heart rate, diastolic–systolic volumes (EDV/ESV), stroke volume, cardiac output, shortening fraction, and ejection fraction were obtained by the DLC-trained model and then compared to the previous published methods, Time Series Analysis and Kymograph. This new method has several advantages, having full automation, precise detection, and real-time labelling. This network was also trained to analyze zebrafish with cardiovascular defects (pericardial edema) induced by chemical treatments with ethanol and ponatinib. It was revealed that the heart rate, EDV/ESV, stroke volume, and cardiac output from both the ethanol and ponatinib groups displayed significant reductions compared with the control. Hopefully, this trained DLC network can contribute to a better understanding and investigation of the existing cardiovascular system and abnormalities. DeepLabCut (DLC) is a deep learning-based tool initially invented for markerless pose estimation in mammals. In this study, we explored the possibility of adopting this tool for conducting markerless cardiac physiology assessment in an important aquatic toxicology model of zebrafish (Danio rerio). Initially, high-definition videography was applied to capture heartbeat information at a frame rate of 30 frames per second (fps). Next, 20 videos from different individuals were used to perform convolutional neural network training by labeling the heart chamber (ventricle) with eight landmarks. Using Residual Network (ResNet) 152, a neural network with 152 convolutional neural network layers with 500,000 iterations, we successfully obtained a trained model that can track the heart chamber in a real-time manner. Later, we validated DLC performance with the previously published ImageJ Time Series Analysis (TSA) and Kymograph (KYM) methods. We also evaluated DLC performance by challenging experimental animals with ethanol and ponatinib to induce cardiac abnormality and heartbeat irregularity. The results showed that DLC is more accurate than the TSA method in several parameters tested. The DLC-trained model also detected the ventricle of zebrafish embryos even in the occurrence of heart abnormalities, such as pericardial edema. We believe that this tool is beneficial for research studies, especially for cardiac physiology assessment in zebrafish embryos.
J2  - Biology
SP  - 1243
IS  - 8
VL  - 11
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/20ed129f-9587-4538-a5b0-e91d8d90578d
XX  - 
PMID  - 36009871
ER  - 

TY  - JOUR
TI  - Acoustic camera system for measuring ultrasound communication in mice
AU  - Matsumoto, Jumpei
AU  - Kanno, Kouta
AU  - Kato, Masahiro
AU  - Nishimaru, Hiroshi
AU  - Setogawa, Tsuyoshi
AU  - Chinzorig, Choijiljav
AU  - Shibata, Tomohiro
AU  - Nishijo, Hisao
T2  - iScience
SN  - 2589-0042
DO  - 10.1016/j.isci.2022.104812
U1  - 35982786
U2  - PMC9379670
AB  - To investigate biological mechanisms underlying social behaviors and their deficits, social communication via ultrasonic vocalizations (USVs) in mice has received considerable attention as a powerful experimental model. The advances in sound localization technology have facilitated the analysis of vocal interactions between multiple mice. However, existing sound localization systems are built around distributed-microphone arrays, which require a special recording arena and long processing time. Here, we report a novel acoustic camera system, USVCAM, which enables simpler and faster USV localization and assignment. The system comprises recently developed USV segmentation algorithms with a modification for overlapping vocalizations that results in high accuracy. Using USVCAM, we analyzed USV communications in a conventional home cage, and demonstrated novel vocal interactions in female ICR mice under a resident-intruder paradigm. The extended applicability and usability of USVCAM may facilitate future studies investigating typical and atypical vocal communication and social behaviors, as well as the underlying mechanisms.
J2  - iScience
SP  - 104812
IS  - 8
VL  - 25
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/4081df00-35dc-4912-bd37-3f29c3113f11
XX  - 
PMID  - 35982786
ER  - 

TY  - JOUR
TI  - Five ways deep learning has transformed image analysis
AU  - Ravindran, Sandeep
T2  - Nature
SN  - 0028-0836
DO  - 10.1038/d41586-022-02964-6
U1  - 36127440
AB  - From connectomics to behavioural biology, artificial intelligence is making it faster and easier to extract information from images. From connectomics to behavioural biology, artificial intelligence is making it faster and easier to extract information from images.
J2  - Nature
SP  - 864-866
IS  - 7928
VL  - 609
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/4e643117-00ba-49f1-abd0-53e893f86c95
XX  - 
PMID  - 36127440
ER  - 

TY  - JOUR
TI  - Dynamic influences on the neural encoding of social valence
AU  - Padilla-Coreano, Nancy
AU  - Tye, Kay M.
AU  - Zelikowsky, Moriel
T2  - Nature Reviews Neuroscience
SN  - 1471-003X
DO  - 10.1038/s41583-022-00609-1
U1  - 35831442
U2  - PMC9997616
AB  - Social signals can serve as potent emotional triggers with powerful impacts on processes from cognition to valence processing. How are social signals dynamically and flexibly associated with positive or negative valence? How do our past social experiences and present social standing shape our motivation to seek or avoid social contact? We discuss a model in which social attributes, social history, social memory, social rank and social isolation can flexibly influence valence assignment to social stimuli, termed here as ‘social valence’. We emphasize how the brain encodes each of these four factors and highlight the neural circuits and mechanisms that play a part in the perception of social attributes, social memory and social rank, as well as how these factors affect valence systems associated with social stimuli. We highlight the impact of social isolation, dissecting the neural and behavioural mechanisms that mediate the effects of acute versus prolonged periods of social isolation. Importantly, we discuss conceptual models that may account for the potential shift in valence of social stimuli from positive to negative as the period of isolation extends in time. Collectively, this Review identifies factors that control the formation and attribution of social valence — integrating diverse areas of research and emphasizing their unique contributions to the categorization of social stimuli as positive or negative. Social valence — the valence assigned to a social agent or social stimulus — is complex to compute. In this Review, Padilla-Coreano et al. explain how social attributes, social history, social memory, social rank and social isolation states are integrated to modulate social valence assignment.
J2  - Nat. Rev. Neurosci.
SP  - 535-550
IS  - 9
VL  - 23
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/e8bc7c0d-ea44-47b7-9037-524480ac985e
XX  - 
PMID  - 35831442
ER  - 

TY  - JOUR
TI  - EcoPhysioMechanics: Integrating Energetics and Biomechanics to Understand Fish Locomotion under Climate Change
AU  - Santo, Valentina Di
T2  - Integrative And Comparative Biology
SN  - 1540-7063
DO  - 10.1093/icb/icac095
U1  - 35759407
U2  - PMC9494520
AB  - Ecological physiologists and biomechanists have investigated swimming performance in a diversity of fishes; however, the connection between form, function, and energetics of locomotion has been rarely evaluated in the same system and under climate change scenarios. In this perspective, I argue that working within the framework of “EcoPhysioMechanics,” i.e. integrating energetics and biomechanics tools, to measure locomotor performance and behavior under different abiotic factors, improves our understanding of the mechanisms, limits and costs of movement. To demonstrate how EcoPhysioMechanics can be applied to locomotor studies, I outline how linking biomechanics and physiology allows us to understand how fishes may modulate their movement to achieve high speeds or reduce the costs of locomotion. I also discuss how the framework is necessary to quantify swimming capacity under climate change scenarios. Finally, I discuss current dearth of integrative studies and gaps in empirical datasets that are necessary to understand fish swimming under changing environments.
J2  - Integr. Comp. Biol.
SP  - 711-720
IS  - 3
VL  - 62
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/2a806be5-cb72-40f1-8223-2ad140223b3b
XX  - 
PMID  - 35759407
ER  - 

TY  - JOUR
TI  - Advancements in Genomic and Behavioral Neuroscience Analysis for the Study of Normal and Pathological Brain Function
AU  - Baratta, Annalisa M.
AU  - Brandner, Adam J.
AU  - Plasil, Sonja L.
AU  - Rice, Rachel C.
AU  - Farris, Sean P.
T2  - Frontiers in Molecular Neuroscience
SN  - 1662-5099
DO  - 10.3389/fnmol.2022.905328
U1  - 35813067
U2  - PMC9259865
AB  - Psychiatric and neurological disorders are influenced by an undetermined number of genes and molecular pathways that may differ among afflicted individuals. Functionally testing and characterizing biological systems is essential to discovering the interrelationship among candidate genes and understanding the neurobiology of behavior. Recent advancements in genetic, genomic, and behavioral approaches are revolutionizing modern neuroscience. Although these tools are often used separately for independent experiments, combining these areas of research will provide a viable avenue for multidimensional studies on the brain. Herein we will briefly review some of the available tools that have been developed for characterizing novel cellular and animal models of human disease. A major challenge will be openly sharing resources and datasets to effectively integrate seemingly disparate types of information and how these systems impact human disorders. However, as these emerging technologies continue to be developed and adopted by the scientific community, they will bring about unprecedented opportunities in our understanding of molecular neuroscience and behavior.
J2  - Front. Mol. Neurosci.
SP  - 905328
VL  - 15
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/480012a6-9ee7-4f25-9fae-a921cdc02a94
XX  - 
PMID  - 35813067
ER  - 

TY  - JOUR
TI  - Neural mechanisms underlying the temporal organization of naturalistic animal behavior
AU  - Mazzucato, Luca
T2  - eLife
DO  - 10.7554/elife.76577
U1  - 35792884
U2  - PMC9259028
AB  - Naturalistic animal behavior exhibits a strikingly complex organization in the temporal domain, with variability arising from at least three sources: hierarchical, contextual, and stochastic. What neural mechanisms and computational principles underlie such intricate temporal features? In this review, we provide a critical assessment of the existing behavioral and neurophysiological evidence for these sources of temporal variability in naturalistic behavior. Recent research converges on an emergent mechanistic theory of temporal variability based on attractor neural networks and metastable dynamics, arising via coordinated interactions between mesoscopic neural circuits. We highlight the crucial role played by structural heterogeneities as well as noise from mesoscopic feedback loops in regulating flexible behavior. We assess the shortcomings and missing links in the current theoretical and experimental literature and propose new directions of investigation to fill these gaps.
J2  - eLife
SP  - e76577
VL  - 11
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/f620b986-ca6e-4e59-bd11-c3254f87ba9d
XX  - 
PMID  - 35792884
ER  - 

TY  - JOUR
TI  - Measuring Locomotor Activity and Behavioral Aspects of Rodents Living in the Home-Cage
AU  - Klein, Christian J. M. I.
AU  - Budiman, Thomas
AU  - Homberg, Judith R.
AU  - Verma, Dilip
AU  - Keijer, Jaap
AU  - Schothorst, Evert M. van
T2  - Frontiers in Behavioral Neuroscience
SN  - 1662-5153
DO  - 10.3389/fnbeh.2022.877323
U1  - 35464142
U2  - PMC9021872
AB  - Automatization and technological advances have led to a larger number of methods and systems to monitor and measure locomotor activity and more specific behavior of a wide variety of animal species in various environmental conditions in laboratory settings. In rodents, the majority of these systems require the animals to be temporarily taken away from their home-cage into separate observation cage environments which requires manual handling and consequently evokes distress for the animal and may alter behavioral responses. An automated high-throughput approach can overcome this problem. Therefore, this review describes existing automated methods and technologies which enable the measurement of locomotor activity and behavioral aspects of rodents in their most meaningful and stress-free laboratory environment: the home-cage. In line with the Directive 2010/63/EU and the 3R principles (replacement, reduction, refinement), this review furthermore assesses their suitability and potential for group-housed conditions as a refinement strategy, highlighting their current technological and practical limitations. It covers electrical capacitance technology and radio-frequency identification (RFID), which focus mainly on voluntary locomotor activity in both single and multiple rodents, respectively. Infrared beams and force plates expand the detection beyond locomotor activity toward basic behavioral traits but discover their full potential in individually housed rodents only. Despite the great premises of these approaches in terms of behavioral pattern recognition, more sophisticated methods, such as (RFID-assisted) video tracking technology need to be applied to enable the automated analysis of advanced behavioral aspects of individual animals in social housing conditions.
J2  - Front. Behav. Neurosci.
SP  - 877323
VL  - 16
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/3e615804-7753-46ef-9621-b7ab0368d0d1
XX  - 
PMID  - 35464142
ER  - 

TY  - JOUR
TI  - Selfee, self-supervised features extraction of animal behaviors
AU  - Jia, Yinjun
AU  - Li, Shuaishuai
AU  - Guo, Xuan
AU  - Lei, Bo
AU  - Hu, Junqiang
AU  - Xu, Xiao-Hong
AU  - Zhang, Wei
T2  - eLife
DO  - 10.7554/elife.76218
U1  - 35708244
U2  - PMC9296132
AB  - Fast and accurately characterizing animal behaviors is crucial for neuroscience research. Deep learning models are efficiently used in laboratories for behavior analysis. However, it has not been achieved to use an end-to-end unsupervised neural network to extract comprehensive and discriminative features directly from social behavior video frames for annotation and analysis purposes. Here, we report a self-supervised feature extraction (Selfee) convolutional neural network with multiple downstream applications to process video frames of animal behavior in an end-to-end way. Visualization and classification of the extracted features (Meta-representations) validate that Selfee processes animal behaviors in a way similar to human perception. We demonstrate that Meta-representations can be efficiently used to detect anomalous behaviors that are indiscernible to human observation and hint in-depth analysis. Furthermore, time-series analyses of Meta-representations reveal the temporal dynamics of animal behaviors. In conclusion, we present a self-supervised learning approach to extract comprehensive and discriminative features directly from raw video recordings of animal behaviors and demonstrate its potential usage for various downstream applications.
J2  - eLife
SP  - e76218
VL  - 11
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/4db814c4-87e5-44c7-8b7a-1caac505a331
XX  - 
PMID  - 35708244
ER  - 

TY  - JOUR
TI  - Mackenzie Weygandt Mathis
AU  - Marx, Vivien
T2  - Nature Methods
SN  - 1548-7091
DO  - 10.1038/s41592-022-01438-x
U1  - 35414126
AB  - Building a sustainable open source toolbox to track social behavior and how to get in the zone.
J2  - Nat. Methods
SP  - 373-373
IS  - 4
VL  - 19
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/96dda272-cb99-404a-ab85-f52d15b6470e
XX  - 
PMID  - 35414126
ER  - 

TY  - JOUR
TI  - Neural circuits regulating prosocial behaviors
AU  - Walsh, Jessica J.
AU  - Christoffel, Daniel J.
AU  - Malenka, Robert C.
T2  - Neuropsychopharmacology
SN  - 0893-133X
DO  - 10.1038/s41386-022-01348-8
U1  - 35701550
U2  - PMC9700801
AB  - Positive, prosocial interactions are essential for survival, development, and well-being. These intricate and complex behaviors are mediated by an amalgamation of neural circuit mechanisms working in concert. Impairments in prosocial behaviors, which occur in a large number of neuropsychiatric disorders, result from disruption of the coordinated activity of these neural circuits. In this review, we focus our discussion on recent findings that utilize modern approaches in rodents to map, monitor, and manipulate neural circuits implicated in a variety of prosocial behaviors. We highlight how modulation by oxytocin, serotonin, and dopamine of excitatory and inhibitory synaptic transmission in specific brain regions is critical for regulation of adaptive prosocial interactions. We then describe how recent findings have helped elucidate pathophysiological mechanisms underlying the social deficits that accompany neuropsychiatric disorders. We conclude by discussing approaches for the development of more efficacious and targeted therapeutic interventions to ameliorate aberrant prosocial behaviors.
J2  - Neuropsychopharmacology
SP  - 79-89
IS  - 1
VL  - 48
PY  - 2023
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/a56a2641-c964-40a2-9c86-7d9524f91f03
XX  - 
PMID  - 35701550
ER  - 

TY  - JOUR
TI  - Deep-learning-based identification, tracking, pose estimation and behaviour classification of interacting primates and mice in complex environments
AU  - Marks, Markus
AU  - Jin, Qiuhan
AU  - Sturman, Oliver
AU  - Ziegler, Lukas von
AU  - Kollmorgen, Sepp
AU  - Behrens, Wolfger von der
AU  - Mante, Valerio
AU  - Bohacek, Johannes
AU  - Yanik, Mehmet Fatih
T2  - Nature Machine Intelligence
SN  - 2522-5839
DO  - 10.1038/s42256-022-00477-5
U1  - 35465076
U2  - PMC7612650
AB  - Quantification of behaviours of interest from video data is commonly used to study brain function, the effects of pharmacological interventions, and genetic alterations. Existing approaches lack the capability to analyse the behaviour of groups of animals in complex environments. We present a novel deep learning architecture for classifying individual and social animal behaviour—even in complex environments directly from raw video frames—that requires no intervention after initial human supervision. Our behavioural classifier is embedded in a pipeline (SIPEC) that performs segmentation, identification, pose-estimation and classification of complex behaviour, outperforming the state of the art. SIPEC successfully recognizes multiple behaviours of freely moving individual mice as well as socially interacting non-human primates in three dimensions, using data only from simple mono-vision cameras in home-cage set-ups. The use of deep neural networks for the automated analysis of behavioural videos has emerged as a tool in neuroscience, medicine and psychology. Marks and colleagues present a pipeline capable of tracking and identifying animals, as well as classifying individual and interacting animal behaviour in video recordings and even in complex environments.
J2  - Nat. Mach. Intell.
SP  - 331-340
IS  - 4
VL  - 4
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/ae011adb-2df7-44da-8967-b3dab2bd06b2
XX  - 
PMID  - 35465076
ER  - 

TY  - JOUR
TI  - Tracking Highly Similar Rat Instances under Heavy Occlusions: An Unsupervised Deep Generative Pipeline
AU  - Gelencsér-Horváth, Anna
AU  - Kopácsi, László
AU  - Varga, Viktor
AU  - Keller, Dávid
AU  - Dobolyi, Árpád
AU  - Karacs, Kristóf
AU  - Lőrincz, András
T2  - Journal of Imaging
DO  - 10.3390/jimaging8040109
U1  - 35448236
U2  - PMC9026709
AB  - Identity tracking and instance segmentation are crucial in several areas of biological research. Behavior analysis of individuals in groups of similar animals is a task that emerges frequently in agriculture or pharmaceutical studies, among others. Automated annotation of many hours of surveillance videos can facilitate a large number of biological studies/experiments, which otherwise would not be feasible. Solutions based on machine learning generally perform well in tracking and instance segmentation; however, in the case of identical, unmarked instances (e.g., white rats or mice), even state-of-the-art approaches can frequently fail. We propose a pipeline of deep generative models for identity tracking and instance segmentation of highly similar instances, which, in contrast to most region-based approaches, exploits edge information and consequently helps to resolve ambiguity in heavily occluded cases. Our method is trained by synthetic data generation techniques, not requiring prior human annotation. We show that our approach greatly outperforms other state-of-the-art unsupervised methods in identity tracking and instance segmentation of unmarked rats in real-world laboratory video recordings.
J2  - J. Imaging
SP  - 109
IS  - 4
VL  - 8
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/cc0ee539-aae6-4650-b982-fd4737706482
XX  - 
PMID  - 35448236
ER  - 

TY  - JOUR
TI  - Visual Field Analysis: A reliable method to score left and right eye use using automated tracking
AU  - Josserand, Mathilde
AU  - Rosa-Salva, Orsola
AU  - Versace, Elisabetta
AU  - Lemaire, Bastien S.
T2  - Behavior Research Methods
SN  - 1554-351X
DO  - 10.3758/s13428-021-01702-6
U1  - 34625917
U2  - PMC9374601
AB  - Brain and behavioural asymmetries have been documented in various taxa. Many of these asymmetries involve preferential left and right eye use. However, measuring eye use through manual frame-by-frame analyses from video recordings is laborious and may lead to biases. Recent progress in technology has allowed the development of accurate tracking techniques for measuring animal behaviour. Amongst these techniques, DeepLabCut, a Python-based tracking toolbox using transfer learning with deep neural networks, offers the possibility to track different body parts with unprecedented accuracy. Exploiting the potentialities of DeepLabCut, we developed Visual Field Analysis, an additional open-source application for extracting eye use data. To our knowledge, this is the first application that can automatically quantify left–right preferences in eye use. Here we test the performance of our application in measuring preferential eye use in young domestic chicks. The comparison with manual scoring methods revealed a near perfect correlation in the measures of eye use obtained by Visual Field Analysis. With our application, eye use can be analysed reliably, objectively and at a fine scale in different experimental paradigms.
J2  - Behav. Res. Methods
SP  - 1715-1724
IS  - 4
VL  - 54
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/8e99f432-b27b-4207-9072-9d1e14a6b3d2
XX  - 
PMID  - 34625917
ER  - 

TY  - JOUR
TI  - Social behavior: Using visual cues to guide dancing on the fly
AU  - Gordus, Andrew
T2  - Current Biology
SN  - 0960-9822
DO  - 10.1016/j.cub.2022.02.053
U1  - 35349817
U2  - PMC10484333
AB  - Quantitative behavioral analysis of Drosophila courtship reveals that visual cues of a female’s body influence which actions a male performs during courtship. These actions in turn influence female actions, producing a mutual synchronization of courtship between male and female flies.
J2  - Curr. Biol.
SP  - R284-R287
IS  - 6
VL  - 32
PY  - 2022
UR  - https://app.readcube.com/library/22d5134f-78fc-4e5e-8838-ad0b40bbacd3/item/c110f26c-6031-44ea-8e03-b5456062e0ab
XX  - 
PMID  - 35349817
ER  - 

