{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse \n",
    "import taxonomic_classification\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import Entrez\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. With `count_keywords` function we get number of articles that cite deeplabcut for each specie. Notice that the function is designed to exclude \"others\" category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the RIS file: 63\n"
     ]
    }
   ],
   "source": [
    "df = parse.count_keywords(file_name='madlc_pubmed.ris', include_titles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Since this function takes a bit long, let's save the output as a pickle file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('count_keywords_pubmed.pkl', 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Loading the dictionary `count_keyword.pkl` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('count_keywords.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. From the dictionary, get animal list, without conts, only animal's name/label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the dictionary, get animal list, without counts, only animal name/label.\n",
    "animal_list = list(df.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish',\n",
       " 'mouse',\n",
       " 'fly',\n",
       " 'primate',\n",
       " 'dog',\n",
       " 'sheep',\n",
       " 'rodent',\n",
       " 'antelope',\n",
       " 'ant',\n",
       " 'jellyfish',\n",
       " 'crab']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 1,\n",
       " 'titles': ['Evaluation of Sexual Behavior in Laboratory vs Seminatural Conditions']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['insect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert this list of common names to list of scientific names. \n",
    "\n",
    "The NCBI E-utilities we are using require an email address to be specified. So first, we need to set our email before making the API calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientific_names = taxonomic_classification.common_to_scientific_names(animal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_to_scientific(common_names:list):\n",
    "    \"\"\"\n",
    "    Convert a list of specific animal species to their corresponding scientific names.\n",
    "    Broad categories like 'primate' or 'crab' are left as common names.\n",
    "\n",
    "    Args:\n",
    "        common_names (list): A list of common animal names.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of scientific names corresponding to the input common names.\n",
    "              If a common name cannot be found or is a broad category, the corresponding entry in the list remains unchanged.\n",
    "    \"\"\"\n",
    "    specific_species = ['mouse', 'dog', 'sheep', 'antelope', 'ant', 'jellyfish']  # Add more specific species here\n",
    "    scientific_names = []\n",
    "    \n",
    "    for common_name in common_names:\n",
    "        if common_name not in specific_species:\n",
    "            scientific_names.append(common_name)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            handle = Entrez.esearch(db=\"taxonomy\", term=f\"{common_name}[Common Name]\")\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "\n",
    "            if record[\"Count\"] == \"0\":\n",
    "                scientific_names.append(common_name)  # Keep the common name if no scientific name is found\n",
    "            else:\n",
    "                taxid = record[\"IdList\"][0]\n",
    "                handle = Entrez.efetch(db=\"taxonomy\", id=taxid, retmode=\"xml\")\n",
    "                records = Entrez.read(handle)\n",
    "                handle.close()\n",
    "                scientific_name = records[0][\"ScientificName\"]\n",
    "                scientific_names.append(scientific_name)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for '{common_name}': {str(e)}\")\n",
    "            scientific_names.append(common_name)  # Keep the common name in case of an error\n",
    "\n",
    "    return scientific_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = common_to_scientific(animal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish',\n",
       " 'Mus musculus',\n",
       " 'fly',\n",
       " 'primate',\n",
       " 'Canis lupus familiaris',\n",
       " 'Ovis aries',\n",
       " 'rodent',\n",
       " 'antelope',\n",
       " 'ant',\n",
       " 'jellyfish',\n",
       " 'crab']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyanimals(animal_list:list, api_key:str):\n",
    "    \"\"\"\n",
    "    Classify a list of animals based on their scientific names using the NCBI Taxonomy Database.\n",
    "\n",
    "    Args:\n",
    "        animal_list (list): A list of scientific names of animals to be classified.\n",
    "        api_key (str): A valid API key for access to NCBI services. You need a user in the NCBI server and\n",
    "                find the API keys in user settings. \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing taxonomic data for the given animals retrieved from the NCBI Taxonomy Database.\n",
    "                     The DataFrame includes information about the animals' classification at various taxonomic levels.\n",
    "                     If a classification fails for an animal, the corresponding row in the DataFrame will contain None.\n",
    "    \"\"\"\n",
    "    Entrez.api_key = api_key\n",
    "    results = []\n",
    "    for animal in animal_list:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db=\"taxonomy\", term=animal)\n",
    "            record = Entrez.read(handle)\n",
    "\n",
    "            if record[\"IdList\"]:\n",
    "                taxid = record[\"IdList\"][0]\n",
    "                handle = Entrez.efetch(db=\"taxonomy\", id=taxid, retmode=\"xml\")\n",
    "                records = Entrez.read(handle)\n",
    "                taxonomy_data = records[0]\n",
    "                results.append(taxonomy_data)\n",
    "            else:\n",
    "                results.append(None)  # Add None if no ID is found\n",
    "        except HTTPError as e:\n",
    "            print(f\"HTTPError for '{animal}': {e}\")\n",
    "            results.append(None)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/annateruel/scipaper_parser/demo_notebook.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/annateruel/scipaper_parser/demo_notebook.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m r \u001b[39m=\u001b[39m classifyanimals(sn, api_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m551e53dbe190f57bbd7cf1784ecd3e72b509\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/annateruel/scipaper_parser/demo_notebook.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annateruel/scipaper_parser/demo_notebook.ipynb#X40sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHTTPError for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00manimal\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annateruel/scipaper_parser/demo_notebook.ipynb#X40sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         results\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/annateruel/scipaper_parser/demo_notebook.ipynb#X40sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(results)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annateruel/scipaper_parser/demo_notebook.ipynb#X40sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/core/frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 746\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    747\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    749\u001b[0m         data,\n\u001b[1;32m    750\u001b[0m         columns,\n\u001b[1;32m    751\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    752\u001b[0m         dtype,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m         arrays,\n\u001b[1;32m    756\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/core/internals/construction.py:867\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    865\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m    866\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], abc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m--> 867\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m    869\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/core/internals/construction.py:947\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[0;34m(data, columns)\u001b[0m\n\u001b[1;32m    945\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[1;32m    946\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[0;32m--> 947\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39;49msort)\n\u001b[1;32m    948\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(pre_cols)\n\u001b[1;32m    950\u001b[0m \u001b[39m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m# classes\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/_libs/lib.pyx:419\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlc_analysis/lib/python3.10/site-packages/pandas/core/internals/construction.py:945\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39mcolumns : Index\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39;49mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[1;32m    946\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[1;32m    947\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39msort)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "r = classifyanimals(sn, api_key='551e53dbe190f57bbd7cf1784ecd3e72b509')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coelacanthimorpha',\n",
       " 'Mus musculus',\n",
       " 'Canis lupus familiaris',\n",
       " 'Ovis aries',\n",
       " 'Rodentia']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list = [item for item in scientific_names if item is not None]\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Classify a list of animals based on their scientific names using the NCBI Taxonomy Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data = taxonomic_classification.classify_animal(animal_list=filtered_list, api_key='551e53dbe190f57bbd7cf1784ecd3e72b509')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Vertebrates\n",
       "1        Rodents\n",
       "2        Mammals\n",
       "3        Mammals\n",
       "4        Rodents\n",
       "Name: Division, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_data['Division']\n",
    "#classified_data['Lineage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def classify(animal_list: list, api_key: str):\n",
    "    itis_url = \"https://www.itis.gov/ITISWebService/jsonservice/searchForAnyMatch?srchKey=\"\n",
    "\n",
    "    categorized_results = []\n",
    "\n",
    "    for animal in animal_list:\n",
    "        try:\n",
    "            response = requests.get(f\"{itis_url}{animal}\")\n",
    "            itis_data = response.json()\n",
    "\n",
    "            if \"commonNames\" in itis_data:\n",
    "                common_names = itis_data[\"commonNames\"]\n",
    "                if common_names:\n",
    "                    common_name = common_names[0].get(\"name\", \"\")\n",
    "                    result = {\"ScientificName\": animal, \"Category\": common_name}\n",
    "                    categorized_results.append(result)\n",
    "            else:\n",
    "                print(f\"No commonNames field in response for '{animal}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for '{animal}': {e}\")\n",
    "\n",
    "    df = pd.DataFrame(categorized_results)\n",
    "    return df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No commonNames field in response for 'fish'\n",
      "No commonNames field in response for 'mouse'\n",
      "No commonNames field in response for 'fly'\n",
      "No commonNames field in response for 'primate'\n",
      "No commonNames field in response for 'dog'\n",
      "No commonNames field in response for 'sheep'\n",
      "No commonNames field in response for 'rodent'\n",
      "No commonNames field in response for 'antelope'\n",
      "No commonNames field in response for 'ant'\n",
      "No commonNames field in response for 'jellyfish'\n",
      "No commonNames field in response for 'crab'\n"
     ]
    }
   ],
   "source": [
    "d = classify(animal_list=animal_list, api_key='551e53dbe190f57bbd7cf1784ecd3e72b509')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
